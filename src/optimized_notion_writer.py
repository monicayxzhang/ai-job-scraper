# optimized_notion_writer.py - ä¼˜åŒ–çš„Notionå†™å…¥å™¨
"""
æ”¯æŒ16å­—æ®µç»“æ„çš„Notionå†™å…¥å™¨ï¼š
1. ç²¾ç®€å­—æ®µç»“æ„ï¼ˆä»24ä¸ªå‡å°‘åˆ°16ä¸ªï¼‰
2. å¢å¼ºç­›é€‰ç»“æœå±•ç¤º
3. ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ
4. å…¼å®¹ç­›é€‰ç³»ç»Ÿè¾“å‡º
"""
import json
import os
import glob
import asyncio
from datetime import datetime
from typing import List, Dict, Any, Optional

try:
    from notion_client import Client
    HAS_NOTION_CLIENT = True
except ImportError:
    HAS_NOTION_CLIENT = False
    print("âš ï¸  è¯·å®‰è£…notion-client: pip install notion-client")

from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
for env_path in [".env", "../.env", "../../.env"]:
    if os.path.exists(env_path):
        load_dotenv(env_path)
        break

class OptimizedNotionJobWriter:
    """ä¼˜åŒ–çš„Notionå²—ä½å†™å…¥å™¨ - 16å­—æ®µç‰ˆæœ¬"""
    
    def __init__(self):
        """åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆNotionå†™å…¥å™¨"""
        if not HAS_NOTION_CLIENT:
            raise ImportError("è¯·å…ˆå®‰è£…notion-client: pip install notion-client")
        
        self.notion_token = os.getenv("NOTION_TOKEN")
        self.database_id = os.getenv("NOTION_DATABASE_ID")
        
        if not self.notion_token:
            raise ValueError("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®NOTION_TOKEN")
        if not self.database_id:
            raise ValueError("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®NOTION_DATABASE_ID")
        
        self.client = Client(auth=self.notion_token)
        print(f"âœ… ä¼˜åŒ–ç‰ˆNotionå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼ˆ16å­—æ®µæ¨¡å¼ï¼‰")
    
    def _create_optimized_notion_properties(self, job_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºä¼˜åŒ–åçš„Notionå±æ€§ - 16ä¸ªæ ¸å¿ƒå­—æ®µ"""
        properties = {}
        
        # 1. æ ¸å¿ƒä¿¡æ¯ (6ä¸ªå­—æ®µ)
        if job_data.get("å²—ä½åç§°"):
            properties["å²—ä½åç§°"] = {
                "title": [{"text": {"content": job_data["å²—ä½åç§°"]}}]
            }
        
        for field in ["å…¬å¸åç§°", "è–ªèµ„", "å·¥ä½œåœ°ç‚¹"]:
            if job_data.get(field):
                properties[field] = {
                    "rich_text": [{"text": {"content": str(job_data[field])}}]
                }
        
        if job_data.get("å²—ä½æè¿°"):
            content = job_data["å²—ä½æè¿°"]
            if len(content) > 2000:
                content = content[:1997] + "..."
            properties["å²—ä½æè¿°"] = {
                "rich_text": [{"text": {"content": content}}]
            }
        
        if job_data.get("å²—ä½é“¾æ¥"):
            properties["å²—ä½é“¾æ¥"] = {"url": job_data["å²—ä½é“¾æ¥"]}
        
        # 2. ç­›é€‰è¯„åˆ† (2ä¸ªå­—æ®µ)
        if job_data.get("ç»¼åˆè¯„åˆ†") is not None:
            # ç¡®ä¿æ˜¯æ•°å­—ç±»å‹
            score = job_data["ç»¼åˆè¯„åˆ†"]
            if isinstance(score, (int, float)):
                properties["ç»¼åˆè¯„åˆ†"] = {"number": score}
            elif isinstance(score, str) and score.isdigit():
                properties["ç»¼åˆè¯„åˆ†"] = {"number": int(score)}
        
        if job_data.get("æ¨èç­‰çº§"):
            properties["æ¨èç­‰çº§"] = {
                "select": {"name": job_data["æ¨èç­‰çº§"]}
            }
        
        # 3. åŒ¹é…åˆ†æ (2ä¸ªå­—æ®µ)
        if job_data.get("ç»éªŒè¦æ±‚"):
            properties["ç»éªŒè¦æ±‚"] = {
                "rich_text": [{"text": {"content": job_data["ç»éªŒè¦æ±‚"]}}]
            }
        
        if job_data.get("ç»éªŒåŒ¹é…å»ºè®®"):
            content = job_data["ç»éªŒåŒ¹é…å»ºè®®"]
            if len(content) > 2000:
                content = content[:1997] + "..."
            properties["ç»éªŒåŒ¹é…å»ºè®®"] = {
                "rich_text": [{"text": {"content": content}}]
            }
        
        # 4. æ—¶é—´ä¿¡æ¯ (2ä¸ªå­—æ®µ) - ä½¿ç”¨æ ‡å‡†åŒ–ç‰ˆæœ¬
        graduation_req = job_data.get("æ¯•ä¸šæ—¶é—´è¦æ±‚_æ ‡å‡†åŒ–", "")
        if graduation_req:
            properties["æ¯•ä¸šæ—¶é—´è¦æ±‚_æ ‡å‡†åŒ–"] = {
                "rich_text": [{"text": {"content": graduation_req}}]
            }
        
        # æ‹›è˜æˆªæ­¢æ—¥æœŸï¼ˆä¼˜å…ˆä½¿ç”¨æ ‡å‡†åŒ–ç‰ˆæœ¬ï¼‰
        deadline = job_data.get("æ‹›è˜æˆªæ­¢æ—¥æœŸ_æ ‡å‡†åŒ–", "")
        if deadline:
            try:
                # å°è¯•ä½œä¸ºæ—¥æœŸå­—æ®µ
                if deadline and len(deadline) == 10 and deadline.count('-') == 2:
                    datetime.strptime(deadline, "%Y-%m-%d")
                    properties["æ‹›è˜æˆªæ­¢æ—¥æœŸ_æ ‡å‡†åŒ–"] = {
                        "date": {"start": deadline}
                    }
                else:
                    # æ ¼å¼é”™è¯¯æ—¶ä½œä¸ºæ–‡æœ¬
                    properties["æ‹›è˜æˆªæ­¢æ—¥æœŸ_æ ‡å‡†åŒ–"] = {
                        "rich_text": [{"text": {"content": deadline}}]
                    }
            except ValueError:
                # æ ¼å¼é”™è¯¯æ—¶ä½œä¸ºæ–‡æœ¬
                properties["æ‹›è˜æˆªæ­¢æ—¥æœŸ_æ ‡å‡†åŒ–"] = {
                    "rich_text": [{"text": {"content": deadline}}]
                }
        
        # 5. è¡¥å……ä¿¡æ¯ (2ä¸ªå­—æ®µ)
        if job_data.get("å‘å¸ƒå¹³å°"):
            properties["å‘å¸ƒå¹³å°"] = {
                "select": {"name": job_data["å‘å¸ƒå¹³å°"]}
            }
        
        if job_data.get("æ‹›å‹Ÿæ–¹å‘"):
            properties["æ‹›å‹Ÿæ–¹å‘"] = {
                "rich_text": [{"text": {"content": job_data["æ‹›å‹Ÿæ–¹å‘"]}}]
            }
        
        # 6. HRå’ŒæŠ“å–ä¿¡æ¯ (2ä¸ªå­—æ®µ)
        if job_data.get("HRæ´»è·ƒåº¦"):
            properties["HRæ´»è·ƒåº¦"] = {
                "rich_text": [{"text": {"content": job_data["HRæ´»è·ƒåº¦"]}}]
            }
        
        if job_data.get("é¡µé¢æŠ“å–æ—¶é—´"):
            crawl_time = job_data["é¡µé¢æŠ“å–æ—¶é—´"]
            try:
                # å°è¯•ä½œä¸ºæ—¥æœŸå­—æ®µ
                if crawl_time and len(str(crawl_time)) >= 10:
                    # æå–æ—¥æœŸéƒ¨åˆ† (YYYY-MM-DD)
                    date_part = str(crawl_time)[:10]
                    if date_part.count('-') == 2:
                        datetime.strptime(date_part, "%Y-%m-%d")
                        properties["é¡µé¢æŠ“å–æ—¶é—´"] = {
                            "date": {"start": date_part}
                        }
                    else:
                        # æ ¼å¼é”™è¯¯æ—¶ä½œä¸ºæ–‡æœ¬
                        properties["é¡µé¢æŠ“å–æ—¶é—´"] = {
                            "rich_text": [{"text": {"content": str(crawl_time)}}]
                        }
                else:
                    # ç©ºå€¼æˆ–æ ¼å¼é”™è¯¯æ—¶ä½œä¸ºæ–‡æœ¬
                    properties["é¡µé¢æŠ“å–æ—¶é—´"] = {
                        "rich_text": [{"text": {"content": str(crawl_time)}}]
                    }
            except (ValueError, TypeError):
                # æ ¼å¼é”™è¯¯æ—¶ä½œä¸ºæ–‡æœ¬
                properties["é¡µé¢æŠ“å–æ—¶é—´"] = {
                    "rich_text": [{"text": {"content": str(crawl_time)}}]
                }
        
        return properties
    
    def get_optimized_notion_fields(self) -> Dict[str, str]:
        """è·å–ä¼˜åŒ–åçš„Notionå­—æ®µå®šä¹‰ï¼ˆå…±16ä¸ªå­—æ®µï¼‰"""
        return {
            # æ ¸å¿ƒä¿¡æ¯ (6ä¸ª)
            "å²—ä½åç§°": "title",
            "å…¬å¸åç§°": "rich_text",
            "è–ªèµ„": "rich_text",
            "å·¥ä½œåœ°ç‚¹": "rich_text",
            "å²—ä½æè¿°": "rich_text",
            "å²—ä½é“¾æ¥": "url",
            
            # ç­›é€‰è¯„åˆ† (2ä¸ª)
            "ç»¼åˆè¯„åˆ†": "number",
            "æ¨èç­‰çº§": "select",
            
            # åŒ¹é…åˆ†æ (2ä¸ª)
            "ç»éªŒè¦æ±‚": "rich_text",
            "ç»éªŒåŒ¹é…å»ºè®®": "rich_text",
            
            # æ—¶é—´ä¿¡æ¯ (2ä¸ª)
            "æ¯•ä¸šæ—¶é—´è¦æ±‚_æ ‡å‡†åŒ–": "rich_text",
            "æ‹›è˜æˆªæ­¢æ—¥æœŸ_æ ‡å‡†åŒ–": "date",  # å¯ä»¥æ˜¯dateæˆ–rich_text
            
            # è¡¥å……ä¿¡æ¯ (2ä¸ª)
            "å‘å¸ƒå¹³å°": "select",
            "æ‹›å‹Ÿæ–¹å‘": "rich_text",
            
            # HRå’ŒæŠ“å–ä¿¡æ¯ (2ä¸ª)
            "HRæ´»è·ƒåº¦": "rich_text",
            "é¡µé¢æŠ“å–æ—¶é—´": "date"  # å¯ä»¥æ˜¯dateæˆ–rich_text
        }
    
    async def create_page_optimized(self, job_data: Dict[str, Any]) -> Optional[str]:
        """åœ¨Notionæ•°æ®åº“ä¸­åˆ›å»ºæ–°é¡µé¢ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        try:
            properties = self._create_optimized_notion_properties(job_data)
            
            if not properties.get("å²—ä½åç§°"):
                print("âš ï¸  å²—ä½åç§°ä¸ºç©ºï¼Œè·³è¿‡åˆ›å»º")
                return None
            
            response = self.client.pages.create(
                parent={"database_id": self.database_id},
                properties=properties
            )
            
            page_id = response["id"]
            job_title = job_data.get("å²—ä½åç§°", "æœªçŸ¥å²—ä½")
            company = job_data.get("å…¬å¸åç§°", "æœªçŸ¥å…¬å¸")
            score = job_data.get("ç»¼åˆè¯„åˆ†", 0)
            level = job_data.get("æ¨èç­‰çº§", "")
            
            # æ ¹æ®æ¨èç­‰çº§æ˜¾ç¤ºä¸åŒçš„æˆåŠŸä¿¡æ¯
            if "å¼ºçƒˆæ¨è" in level:
                print(f"ğŸŒŸ åˆ›å»ºæˆåŠŸã€å¼ºæ¨ã€‘: {job_title} - {company} ({score}åˆ†)")
            elif "æ¨è" in level:
                print(f"âœ¨ åˆ›å»ºæˆåŠŸã€æ¨èã€‘: {job_title} - {company} ({score}åˆ†)")
            elif "å¯è€ƒè™‘" in level:
                print(f"âš ï¸ åˆ›å»ºæˆåŠŸã€å¯è€ƒè™‘ã€‘: {job_title} - {company} ({score}åˆ†)")
            else:
                print(f"âœ… åˆ›å»ºæˆåŠŸ: {job_title} - {company} ({score}åˆ†)")
            
            return page_id
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºé¡µé¢å¤±è´¥: {e}")
            print(f"   å²—ä½: {job_data.get('å²—ä½åç§°', 'N/A')}")
            return None
    
    async def batch_write_jobs_optimized(self, jobs_data: List[Dict[str, Any]], max_concurrent: int = 2) -> Dict[str, int]:
        """æ‰¹é‡å†™å…¥ä¼˜åŒ–çš„å²—ä½æ•°æ®"""
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å†™å…¥ {len(jobs_data)} ä¸ªå²—ä½åˆ°Notionï¼ˆ16å­—æ®µä¼˜åŒ–ç‰ˆï¼‰")
        
        stats = {
            "total": len(jobs_data),
            "success": 0,
            "failed": 0,
            "strongly_recommended": 0,  # ğŸŒŸ å¼ºçƒˆæ¨è
            "recommended": 0,           # âœ¨ æ¨è
            "considerable": 0,          # âš ï¸ å¯è€ƒè™‘
            "not_recommended": 0        # âŒ ä¸æ¨è
        }
        
        # æ§åˆ¶å¹¶å‘æ•°é‡ï¼Œé¿å…APIé™æµ
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def write_single_job(job_data):
            async with semaphore:
                result = await self.create_page_optimized(job_data)
                if result:
                    stats["success"] += 1
                    
                    # ç»Ÿè®¡æ¨èç­‰çº§
                    level = job_data.get("æ¨èç­‰çº§", "")
                    if "å¼ºçƒˆæ¨è" in level:
                        stats["strongly_recommended"] += 1
                    elif "æ¨è" in level:
                        stats["recommended"] += 1
                    elif "å¯è€ƒè™‘" in level:
                        stats["considerable"] += 1
                    else:
                        stats["not_recommended"] += 1
                else:
                    stats["failed"] += 1
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™æµ
                await asyncio.sleep(1)
                return result
        
        # å¹¶å‘æ‰§è¡Œ
        tasks = [write_single_job(job) for job in jobs_data]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ç»Ÿè®¡ç»“æœ
        for result in results:
            if isinstance(result, Exception):
                stats["failed"] += 1
                print(f"âš ï¸  ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {result}")
        
        return stats
    
    def check_database_schema(self) -> bool:
        """æ£€æŸ¥æ•°æ®åº“ç»“æ„æ˜¯å¦åŒ¹é…ï¼ˆä¼˜åŒ–ç‰ˆ16å­—æ®µï¼‰"""
        try:
            database = self.client.databases.retrieve(database_id=self.database_id)
            properties = database["properties"]
            
            print("ğŸ“‹ å½“å‰æ•°æ®åº“å­—æ®µ:")
            for prop_name, prop_info in properties.items():
                prop_type = prop_info["type"]
                print(f"   {prop_name}: {prop_type}")
            
            # æ£€æŸ¥å¿…éœ€çš„16ä¸ªå­—æ®µ
            required_fields = self.get_optimized_notion_fields()
            
            missing_fields = []
            type_mismatches = []
            
            for field_name, expected_type in required_fields.items():
                if field_name not in properties:
                    missing_fields.append(f"{field_name} ({expected_type})")
                else:
                    actual_type = properties[field_name]["type"]
                    # æ‹›è˜æˆªæ­¢æ—¥æœŸå¯ä»¥æ˜¯dateæˆ–rich_text
                    if field_name == "æ‹›è˜æˆªæ­¢æ—¥æœŸ_æ ‡å‡†åŒ–":
                        if actual_type not in ["date", "rich_text"]:
                            type_mismatches.append(f"{field_name}: æœŸæœ›date/rich_textï¼Œå®é™…{actual_type}")
                    elif actual_type != expected_type:
                        type_mismatches.append(f"{field_name}: æœŸæœ›{expected_type}ï¼Œå®é™…{actual_type}")
            
            if missing_fields:
                print(f"âŒ ç¼ºå°‘ä»¥ä¸‹å­—æ®µ:")
                for field in missing_fields:
                    print(f"   - {field}")
                print(f"\nğŸ’¡ è¯·åœ¨Notionæ•°æ®åº“ä¸­æ·»åŠ è¿™äº›å­—æ®µ")
                self._print_schema_guide()
                return False
            
            if type_mismatches:
                print(f"âš ï¸  å­—æ®µç±»å‹ä¸åŒ¹é…:")
                for mismatch in type_mismatches:
                    print(f"   - {mismatch}")
            
            print("âœ… ä¼˜åŒ–æ•°æ®åº“ç»“æ„æ£€æŸ¥é€šè¿‡")
            print(f"ğŸ“Š å­—æ®µç»Ÿè®¡: å½“å‰{len(properties)}ä¸ªï¼Œéœ€è¦{len(required_fields)}ä¸ªï¼Œç²¾ç®€{len(properties)-len(required_fields)}ä¸ª")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _print_schema_guide(self):
        """æ‰“å°æ•°æ®åº“ç»“æ„æŒ‡å—"""
        print(f"\nğŸ“‹ ä¼˜åŒ–ç‰ˆNotionæ•°æ®åº“ç»“æ„æŒ‡å—ï¼ˆ16ä¸ªå­—æ®µï¼‰:")
        
        fields_guide = {
            "æ ¸å¿ƒä¿¡æ¯ (6ä¸ª)": {
                "å²—ä½åç§°": "æ ‡é¢˜ (Title)",
                "å…¬å¸åç§°": "æ–‡æœ¬ (Text)",
                "è–ªèµ„": "æ–‡æœ¬ (Text)",
                "å·¥ä½œåœ°ç‚¹": "æ–‡æœ¬ (Text)",
                "å²—ä½æè¿°": "æ–‡æœ¬ (Text)",
                "å²—ä½é“¾æ¥": "ç½‘å€ (URL)"
            },
            "ç­›é€‰è¯„åˆ† (2ä¸ª)": {
                "ç»¼åˆè¯„åˆ†": "æ•°å­— (Number)",
                "æ¨èç­‰çº§": "é€‰æ‹© (Select) - é€‰é¡¹: ğŸŒŸ å¼ºçƒˆæ¨è, âœ¨ æ¨è, âš ï¸ å¯è€ƒè™‘, âŒ ä¸æ¨è"
            },
            "åŒ¹é…åˆ†æ (2ä¸ª)": {
                "ç»éªŒè¦æ±‚": "æ–‡æœ¬ (Text)",
                "ç»éªŒåŒ¹é…å»ºè®®": "æ–‡æœ¬ (Text)"
            },
            "æ—¶é—´ä¿¡æ¯ (2ä¸ª)": {
                "æ¯•ä¸šæ—¶é—´è¦æ±‚_æ ‡å‡†åŒ–": "æ–‡æœ¬ (Text)",
                "æ‹›è˜æˆªæ­¢æ—¥æœŸ_æ ‡å‡†åŒ–": "æ—¥æœŸ (Date) æˆ– æ–‡æœ¬ (Text)"
            },
            "è¡¥å……ä¿¡æ¯ (2ä¸ª)": {
                "å‘å¸ƒå¹³å°": "é€‰æ‹© (Select) - é€‰é¡¹: Bossç›´è˜, æ™ºè”æ‹›è˜, çŒè˜, æ‹‰å‹¾ç­‰",
                "æ‹›å‹Ÿæ–¹å‘": "æ–‡æœ¬ (Text)"
            },
            "HRå’ŒæŠ“å–ä¿¡æ¯ (2ä¸ª)": {
                "HRæ´»è·ƒåº¦": "æ–‡æœ¬ (Text)",
                "é¡µé¢æŠ“å–æ—¶é—´": "æ—¥æœŸ (Date) æˆ– æ–‡æœ¬ (Text)"
            }
        }
        
        for category, fields in fields_guide.items():
            print(f"\n{category}:")
            for field_name, field_type in fields.items():
                print(f"   â€¢ {field_name}: {field_type}")
        
        print(f"\nğŸ’¡ ç›¸æ¯”åŸç‰ˆæœ¬ï¼Œä¼˜åŒ–åå‡å°‘äº†ä»¥ä¸‹å­—æ®µ:")
        removed_fields = [
            "å‘å¸ƒæ—¥æœŸ", "å‘å¸ƒæ—¥æœŸæ¥æº",
            "æ¯•ä¸šæ—¶é—´è¦æ±‚", "æ¯•ä¸šæ—¶é—´_åŒ¹é…çŠ¶æ€", "æ‹›è˜æˆªæ­¢æ—¥æœŸ", 
            "æ‹›è˜æˆªæ­¢æ—¥æœŸ_çŠ¶æ€", "æ¯•ä¸šæ—¶é—´è¦æ±‚_æ ‡å‡†åŒ–", "æå–æ—¶é—´"
        ]
        for field in removed_fields:
            print(f"   Ã— {field}")


def find_latest_optimized_data():
    """æŸ¥æ‰¾æœ€æ–°çš„ä¼˜åŒ–ç‰ˆå²—ä½æ•°æ®æ–‡ä»¶"""
    patterns = [
        "**/optimized_extraction_*.json",
        "**/filtered_jobs_*.json",
        "**/enhanced_extraction_*.json",
        "**/enhanced_notion_jobs_*.json"
    ]
    
    all_files = []
    for pattern in patterns:
        all_files.extend(glob.glob(pattern, recursive=True))
    
    if not all_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä¼˜åŒ–ç‰ˆå²—ä½æ•°æ®æ–‡ä»¶")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œå¸¦ç­›é€‰çš„æµæ°´çº¿: python integrated_pipeline_with_filters.py")
        return None
    
    latest_file = max(all_files, key=os.path.getmtime)
    print(f"ğŸ“ æ‰¾åˆ°æœ€æ–°ä¼˜åŒ–ç‰ˆæ•°æ®æ–‡ä»¶: {latest_file}")
    return latest_file

def load_optimized_job_data(file_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½ä¼˜åŒ–ç‰ˆå²—ä½æ•°æ®"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not isinstance(data, list):
            print("âŒ æ•°æ®æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›åˆ—è¡¨æ ¼å¼")
            return []
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(data)} ä¸ªä¼˜åŒ–ç‰ˆå²—ä½")
        return data
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return []

def preview_optimized_jobs(jobs_data: List[Dict[str, Any]], limit: int = 5):
    """é¢„è§ˆä¼˜åŒ–ç‰ˆå²—ä½æ•°æ®"""
    print(f"\nğŸ“‹ ä¼˜åŒ–ç‰ˆå²—ä½é¢„è§ˆ (å‰{min(limit, len(jobs_data))}ä¸ª):")
    
    # ç»Ÿè®¡æ¨èç­‰çº§åˆ†å¸ƒ
    level_stats = {}
    for job in jobs_data:
        level = job.get('æ¨èç­‰çº§', 'æœªçŸ¥')
        level_stats[level] = level_stats.get(level, 0) + 1
    
    print(f"\nğŸ“Š æ¨èç­‰çº§åˆ†å¸ƒ:")
    for level, count in level_stats.items():
        percentage = (count / len(jobs_data)) * 100 if jobs_data else 0
        print(f"   {level}: {count}ä¸ª ({percentage:.1f}%)")
    
    for i, job in enumerate(jobs_data[:limit], 1):
        job_name = job.get('å²—ä½åç§°', 'N/A')
        company = job.get('å…¬å¸åç§°', 'N/A')
        score = job.get('ç»¼åˆè¯„åˆ†', 'N/A')
        level = job.get('æ¨èç­‰çº§', 'N/A')
        experience_advice = job.get('ç»éªŒåŒ¹é…å»ºè®®', 'N/A')
        
        print(f"\n  {i}. {job_name} - {company}")
        print(f"     ğŸ“Š ç»¼åˆè¯„åˆ†: {score}åˆ† | â­ æ¨èç­‰çº§: {level}")
        print(f"     ğŸ’¡ ç»éªŒå»ºè®®: {experience_advice}")

async def test_optimized_notion_connection():
    """æµ‹è¯•ä¼˜åŒ–ç‰ˆNotionè¿æ¥"""
    print("ğŸ§ª æµ‹è¯•ä¼˜åŒ–ç‰ˆNotionè¿æ¥...")
    
    try:
        writer = OptimizedNotionJobWriter()
        
        # æ£€æŸ¥æ•°æ®åº“ç»“æ„
        schema_ok = writer.check_database_schema()
        
        if not schema_ok:
            print("\nğŸ’¡ è¯·åœ¨Notionä¸­åˆ›å»ºæ•°æ®åº“ï¼ŒåŒ…å«ä»¥ä¸‹16ä¸ªå­—æ®µ:")
            writer._print_schema_guide()
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Notionè¿æ¥å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¼˜åŒ–ç‰ˆNotionå²—ä½æ•°æ®å†™å…¥å·¥å…·ï¼ˆ16å­—æ®µç‰ˆæœ¬ï¼‰")
    print("=" * 80)
    
    # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
    notion_token = os.getenv("NOTION_TOKEN")
    database_id = os.getenv("NOTION_DATABASE_ID")
    
    if not notion_token:
        print("âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®NOTION_TOKEN")
        print("ğŸ’¡ è·å–Token: https://www.notion.so/my-integrations")
        return
    
    if not database_id:
        print("âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®NOTION_DATABASE_ID")
        print("ğŸ’¡ æ•°æ®åº“IDæ˜¯URLä¸­database/åé¢çš„éƒ¨åˆ†")
        return
    
    print(f"âœ… Notioné…ç½®æ£€æŸ¥é€šè¿‡")
    
    # 2. æµ‹è¯•è¿æ¥
    connection_ok = await test_optimized_notion_connection()
    if not connection_ok:
        return
    
    # 3. æŸ¥æ‰¾ä¼˜åŒ–ç‰ˆæ•°æ®æ–‡ä»¶
    data_file = find_latest_optimized_data()
    if not data_file:
        return
    
    # 4. åŠ è½½æ•°æ®
    jobs_data = load_optimized_job_data(data_file)
    if not jobs_data:
        return
    
    # 5. é¢„è§ˆæ•°æ®
    preview_optimized_jobs(jobs_data)
    
    # 6. ç»Ÿè®¡ä¼˜åŒ–ç‰ˆä¿¡æ¯
    strongly_recommended = sum(1 for job in jobs_data if "å¼ºçƒˆæ¨è" in job.get("æ¨èç­‰çº§", ""))
    recommended = sum(1 for job in jobs_data if "æ¨è" in job.get("æ¨èç­‰çº§", "") and "å¼ºçƒˆ" not in job.get("æ¨èç­‰çº§", ""))
    considerable = sum(1 for job in jobs_data if "å¯è€ƒè™‘" in job.get("æ¨èç­‰çº§", ""))
    
    print(f"\nğŸ“Š å²—ä½è´¨é‡ç»Ÿè®¡:")
    print(f"   ğŸŒŸ å¼ºçƒˆæ¨è: {strongly_recommended}ä¸ª")
    print(f"   âœ¨ æ¨è: {recommended}ä¸ª") 
    print(f"   âš ï¸ å¯è€ƒè™‘: {considerable}ä¸ª")
    print(f"   ğŸ“‹ å­—æ®µä¼˜åŒ–: 24ä¸ªâ†’16ä¸ªæ ¸å¿ƒå­—æ®µ")
    
    # 7. ç¡®è®¤å†™å…¥
    confirm = input(f"\næ˜¯å¦å°† {len(jobs_data)} ä¸ªä¼˜åŒ–ç‰ˆå²—ä½å†™å…¥Notion? (y/N): ").strip().lower()
    if confirm != 'y':
        print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return
    
    # 8. æ‰§è¡Œå†™å…¥
    try:
        writer = OptimizedNotionJobWriter()
        stats = await writer.batch_write_jobs_optimized(jobs_data, max_concurrent=2)
        
        print(f"\n" + "=" * 80)
        print(f"ğŸ‰ ä¼˜åŒ–ç‰ˆæ‰¹é‡å†™å…¥å®Œæˆ!")
        print("=" * 80)
        print(f"ğŸ“Š å†™å…¥ç»Ÿè®¡:")
        print(f"   æ€»æ•°: {stats['total']}")
        print(f"   æˆåŠŸ: {stats['success']}")
        print(f"   å¤±è´¥: {stats['failed']}")
        print(f"   æˆåŠŸç‡: {stats['success']/stats['total']*100:.1f}%")
        
        print(f"\nğŸ¯ å²—ä½è´¨é‡åˆ†å¸ƒ:")
        print(f"   ğŸŒŸ å¼ºçƒˆæ¨è: {stats['strongly_recommended']}ä¸ª")
        print(f"   âœ¨ æ¨è: {stats['recommended']}ä¸ª")
        print(f"   âš ï¸ å¯è€ƒè™‘: {stats['considerable']}ä¸ª")
        print(f"   âŒ ä¸æ¨è: {stats['not_recommended']}ä¸ª")
        
        if stats['strongly_recommended'] > 0:
            print(f"\nğŸ’¡ å»ºè®®ä¼˜å…ˆå…³æ³¨ {stats['strongly_recommended']} ä¸ªå¼ºçƒˆæ¨èçš„å²—ä½ï¼")
        
        print(f"\nğŸ“± Notionä½¿ç”¨æŒ‡å—:")
        print(f"   1. æŒ‰\"ç»¼åˆè¯„åˆ†\"åˆ—é™åºæ’åˆ—æŸ¥çœ‹æœ€ä¼˜å²—ä½")
        print(f"   2. ç­›é€‰\"æ¨èç­‰çº§\" = \"ğŸŒŸ å¼ºçƒˆæ¨è\"æŸ¥çœ‹é¡¶çº§å²—ä½")
        print(f"   3. æŸ¥çœ‹\"ç»éªŒåŒ¹é…å»ºè®®\"åˆ¶å®šç”³è¯·ç­–ç•¥")
        print(f"   4. å…³æ³¨\"æ‹›è˜æˆªæ­¢æ—¥æœŸ_æ ‡å‡†åŒ–\"åˆç†å®‰æ’æ—¶é—´")
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡å†™å…¥å¤±è´¥: {e}")

if __name__ == "__main__":
    if not HAS_NOTION_CLIENT:
        print("è¯·å…ˆå®‰è£…notion-client:")
        print("pip install notion-client")
    else:
        asyncio.run(main())