# data_snapshot.py - æ•°æ®å¿«ç…§ç³»ç»Ÿ
import json
import os
from datetime import datetime
from typing import List, Dict, Any, Optional, Union
from src.logger_config import get_logger

class DataSnapshot:
    """æ•°æ®å¿«ç…§ç®¡ç†å™¨"""
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.snapshots: Dict[str, Dict[str, Any]] = {}
        self.snapshot_dir = "debug/snapshots"
        
        # ç¡®ä¿å¿«ç…§ç›®å½•å­˜åœ¨
        os.makedirs(self.snapshot_dir, exist_ok=True)
        
        self.logger = get_logger()
        self.logger.debug("æ•°æ®å¿«ç…§ç³»ç»Ÿåˆå§‹åŒ–", {"session_id": session_id})
    
    def capture(self, stage: str, data: Any, metadata: Optional[Dict] = None) -> str:
        """
        æ•è·å…³é”®é˜¶æ®µçš„æ•°æ®å¿«ç…§
        
        Args:
            stage: é˜¶æ®µåç§° (å¦‚ "raw_crawl", "dedup_input", "dedup_output")
            data: è¦å¿«ç…§çš„æ•°æ®
            metadata: é¢å¤–çš„å…ƒæ•°æ®ä¿¡æ¯
            
        Returns:
            å¿«ç…§æ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().isoformat()
        metadata = metadata or {}
        
        # ç”Ÿæˆå¿«ç…§æ‘˜è¦
        snapshot_summary = {
            "stage": stage,
            "timestamp": timestamp,
            "metadata": metadata,
            "data_summary": self._summarize_data(data),
            "sample_data": self._get_sample_data(data)
        }
        
        # ä¿å­˜åˆ°å†…å­˜ç´¢å¼•
        self.snapshots[stage] = snapshot_summary
        
        # ä¿å­˜è¯¦ç»†æ•°æ®åˆ°æ–‡ä»¶
        detail_file = os.path.join(self.snapshot_dir, f"{self.session_id}_{stage}.json")
        
        try:
            with open(detail_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=self._json_serializer)
            
            # è®°å½•å¿«ç…§ä¿¡æ¯
            data_count = len(data) if isinstance(data, (list, dict)) else 1
            self.logger.debug(f"æ•°æ®å¿«ç…§å·²ä¿å­˜: {stage}", {
                "file_path": detail_file,
                "data_count": data_count,
                "file_size_kb": round(os.path.getsize(detail_file) / 1024, 2)
            })
            
            # æ§åˆ¶å°ç®€è¦ä¿¡æ¯
            if hasattr(self.logger, 'level') and self.logger.level.value in ['debug', 'trace']:
                print(f"ğŸ“¸ å¿«ç…§ä¿å­˜: {stage} ({data_count} é¡¹) -> {os.path.basename(detail_file)}")
            
            return detail_file
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜å¿«ç…§å¤±è´¥: {stage}", {
                "error": str(e),
                "stage": stage,
                "data_type": type(data).__name__
            }, e)
            return ""
    
    def _summarize_data(self, data: Any) -> Dict[str, Any]:
        """ç”Ÿæˆæ•°æ®æ‘˜è¦"""
        if isinstance(data, list):
            summary = {
                "type": "list",
                "count": len(data)
            }
            
            if data and isinstance(data[0], dict):
                summary["sample_keys"] = list(data[0].keys())
            elif data:
                summary["sample_type"] = type(data[0]).__name__
            
            return summary
            
        elif isinstance(data, dict):
            return {
                "type": "dict",
                "keys": list(data.keys()),
                "key_count": len(data)
            }
        else:
            return {
                "type": type(data).__name__,
                "value_preview": str(data)[:100] + "..." if len(str(data)) > 100 else str(data)
            }
    
    def _get_sample_data(self, data: Any, sample_size: int = 2) -> Any:
        """è·å–æ ·æœ¬æ•°æ®"""
        if isinstance(data, list):
            return data[:sample_size]
        elif isinstance(data, dict):
            return {k: v for i, (k, v) in enumerate(data.items()) if i < sample_size}
        else:
            return data
    
    def _json_serializer(self, obj):
        """JSONåºåˆ—åŒ–è¾…åŠ©å‡½æ•°"""
        if isinstance(obj, datetime):
            return obj.isoformat()
        # å…¶ä»–ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡è½¬ä¸ºå­—ç¬¦ä¸²
        return str(obj)
    
    def save_summary(self) -> str:
        """ä¿å­˜å¿«ç…§æ‘˜è¦ç´¢å¼•"""
        summary_file = os.path.join(self.snapshot_dir, f"{self.session_id}_summary.json")
        
        try:
            # æ·»åŠ ä¼šè¯çº§åˆ«çš„å…ƒæ•°æ®
            summary_data = {
                "session_info": {
                    "session_id": self.session_id,
                    "created_at": datetime.now().isoformat(),
                    "total_snapshots": len(self.snapshots)
                },
                "snapshots": self.snapshots
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            self.logger.success(f"å¿«ç…§æ‘˜è¦å·²ä¿å­˜: {summary_file}", {
                "snapshot_count": len(self.snapshots),
                "stages": list(self.snapshots.keys())
            })
            
            # åˆ›å»ºæœ€æ–°æ‘˜è¦çš„è½¯é“¾æ¥
            latest_summary = os.path.join(self.snapshot_dir, "latest_summary.json")
            self._create_symlink(summary_file, latest_summary)
            
            return summary_file
            
        except Exception as e:
            self.logger.error("ä¿å­˜å¿«ç…§æ‘˜è¦å¤±è´¥", {"error": str(e)}, e)
            return ""
    
    def _create_symlink(self, target: str, link_name: str):
        """åˆ›å»ºè½¯é“¾æ¥ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰"""
        try:
            if os.path.exists(link_name):
                os.remove(link_name)
            
            # å°è¯•åˆ›å»ºè½¯é“¾æ¥
            try:
                os.symlink(os.path.basename(target), link_name)
            except (OSError, NotImplementedError):
                # Windowså¯èƒ½ä¸æ”¯æŒsymlinkï¼Œç›´æ¥å¤åˆ¶
                import shutil
                shutil.copy2(target, link_name)
                
        except Exception as e:
            self.logger.warning(f"åˆ›å»ºè½¯é“¾æ¥å¤±è´¥: {link_name}", {"error": str(e)})
    
    def load_snapshot(self, stage: str) -> Optional[Any]:
        """åŠ è½½æŒ‡å®šé˜¶æ®µçš„å¿«ç…§æ•°æ®"""
        snapshot_file = os.path.join(self.snapshot_dir, f"{self.session_id}_{stage}.json")
        
        if not os.path.exists(snapshot_file):
            self.logger.warning(f"å¿«ç…§æ–‡ä»¶ä¸å­˜åœ¨: {stage}", {"file_path": snapshot_file})
            return None
        
        try:
            with open(snapshot_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.logger.debug(f"å¿«ç…§åŠ è½½æˆåŠŸ: {stage}", {
                "file_path": snapshot_file,
                "data_type": type(data).__name__
            })
            
            return data
            
        except Exception as e:
            self.logger.error(f"åŠ è½½å¿«ç…§å¤±è´¥: {stage}", {
                "file_path": snapshot_file,
                "error": str(e)
            }, e)
            return None
    
    def list_snapshots(self) -> List[str]:
        """åˆ—å‡ºå½“å‰ä¼šè¯çš„æ‰€æœ‰å¿«ç…§"""
        pattern = f"{self.session_id}_*.json"
        snapshot_files = []
        
        for filename in os.listdir(self.snapshot_dir):
            if filename.startswith(f"{self.session_id}_") and filename.endswith('.json'):
                # æå–é˜¶æ®µåç§°
                stage = filename[len(f"{self.session_id}_"):-5]  # ç§»é™¤å‰ç¼€å’Œ.jsonåç¼€
                if stage != "summary":  # æ’é™¤æ‘˜è¦æ–‡ä»¶
                    snapshot_files.append(stage)
        
        return sorted(snapshot_files)
    
    def compare_snapshots(self, stage1: str, stage2: str) -> Dict[str, Any]:
        """å¯¹æ¯”ä¸¤ä¸ªå¿«ç…§çš„æ•°æ®å·®å¼‚"""
        data1 = self.load_snapshot(stage1)
        data2 = self.load_snapshot(stage2)
        
        if data1 is None or data2 is None:
            return {"error": "æ— æ³•åŠ è½½å¿«ç…§æ•°æ®"}
        
        comparison = {
            "stage1": stage1,
            "stage2": stage2,
            "comparison_time": datetime.now().isoformat()
        }
        
        # å¦‚æœéƒ½æ˜¯åˆ—è¡¨ï¼Œå¯¹æ¯”æ•°é‡å’Œå†…å®¹
        if isinstance(data1, list) and isinstance(data2, list):
            comparison.update({
                "type": "list_comparison",
                "stage1_count": len(data1),
                "stage2_count": len(data2),
                "count_diff": len(data2) - len(data1)
            })
            
            # å¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼Œå¯¹æ¯”é”®å€¼
            if data1 and isinstance(data1[0], dict) and data2 and isinstance(data2[0], dict):
                keys1 = set(data1[0].keys()) if data1 else set()
                keys2 = set(data2[0].keys()) if data2 else set()
                
                comparison.update({
                    "keys_added": list(keys2 - keys1),
                    "keys_removed": list(keys1 - keys2),
                    "common_keys": list(keys1 & keys2)
                })
        
        elif isinstance(data1, dict) and isinstance(data2, dict):
            keys1 = set(data1.keys())
            keys2 = set(data2.keys())
            
            comparison.update({
                "type": "dict_comparison",
                "stage1_keys": len(keys1),
                "stage2_keys": len(keys2),
                "keys_added": list(keys2 - keys1),
                "keys_removed": list(keys1 - keys2),
                "common_keys": list(keys1 & keys2)
            })
        
        self.logger.debug(f"å¿«ç…§å¯¹æ¯”å®Œæˆ: {stage1} vs {stage2}", comparison)
        return comparison

# ä¾¿æ·å‡½æ•°
def create_snapshot_manager(session_id: Optional[str] = None) -> DataSnapshot:
    """åˆ›å»ºæ•°æ®å¿«ç…§ç®¡ç†å™¨"""
    if session_id is None:
        # ä»å…¨å±€loggerè·å–session_id
        logger = get_logger()
        session_id = getattr(logger, 'session_id', datetime.now().strftime("%Y%m%d_%H%M%S"))
    
    return DataSnapshot(session_id)

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
if __name__ == "__main__":
    from src.logger_config import init_logger, LogLevel
    
    print("ğŸ§ª æµ‹è¯•æ•°æ®å¿«ç…§ç³»ç»Ÿ...")
    
    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    logger = init_logger(LogLevel.DEBUG)
    
    # åˆ›å»ºå¿«ç…§ç®¡ç†å™¨
    snapshot = create_snapshot_manager()
    
    # æµ‹è¯•æ•°æ®
    test_jobs = [
        {
            "å²—ä½åç§°": "æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ",
            "å…¬å¸åç§°": "åä¸ºæŠ€æœ¯æœ‰é™å…¬å¸",
            "å·¥ä½œåœ°ç‚¹": "åŒ—äº¬",
            "å²—ä½é“¾æ¥": "https://example.com/job1"
        },
        {
            "å²—ä½åç§°": "æ·±åº¦å­¦ä¹ å·¥ç¨‹å¸ˆ", 
            "å…¬å¸åç§°": "å­—èŠ‚è·³åŠ¨",
            "å·¥ä½œåœ°ç‚¹": "åŒ—äº¬",
            "å²—ä½é“¾æ¥": "https://example.com/job2"
        }
    ]
    
    # æ•è·å¿«ç…§
    snapshot.capture("test_input", test_jobs, {"stage": "æµ‹è¯•è¾“å…¥", "source": "æµ‹è¯•"})
    
    # ä¿®æ”¹æ•°æ®åå†æ¬¡å¿«ç…§
    filtered_jobs = [test_jobs[0]]  # æ¨¡æ‹Ÿå»é‡
    snapshot.capture("test_output", filtered_jobs, {"stage": "æµ‹è¯•è¾“å‡º", "filter": "å»é‡"})
    
    # ä¿å­˜æ‘˜è¦
    snapshot.save_summary()
    
    # æµ‹è¯•å¯¹æ¯”
    comparison = snapshot.compare_snapshots("test_input", "test_output")
    print(f"ğŸ“Š å¿«ç…§å¯¹æ¯”ç»“æœ: {json.dumps(comparison, ensure_ascii=False, indent=2)}")
    
    print("\nâœ… æ•°æ®å¿«ç…§ç³»ç»Ÿæµ‹è¯•å®Œæˆ!")
    print("ğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶:")
    print("   - debug/snapshots/*_summary.json")
    print("   - debug/snapshots/*_test_input.json")
    print("   - debug/snapshots/*_test_output.json")