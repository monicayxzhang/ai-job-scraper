# unified_filter_system.py - ç»Ÿä¸€çš„åˆ†å±‚ç­›é€‰ç³»ç»Ÿ
"""
åˆå¹¶job_filter_systemå’Œoptimized_filter_systemï¼Œæä¾›å®Œæ•´çš„ç­›é€‰è§£å†³æ–¹æ¡ˆï¼š
1. åŸºç¡€ç­›é€‰ï¼šç¡¬æ€§æ¡ä»¶è¿‡æ»¤ï¼ˆè–ªèµ„ã€åœ°ç‚¹ã€ç»éªŒã€æ¯•ä¸šæ—¶é—´ã€æˆªæ­¢æ—¥æœŸï¼‰
2. é«˜çº§ç­›é€‰ï¼šæ™ºèƒ½è¯„åˆ†æ’åºï¼ˆå…¬å¸çŸ¥ååº¦ã€ä¸šåŠ¡é¢†åŸŸåŒ¹é…ï¼‰
3. ç»Ÿä¸€é…ç½®ç®¡ç†
4. ç®€åŒ–Notionå­—æ®µç»“æ„
"""
import re
import json
import os
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
from datetime import datetime, timedelta

class FilterType(Enum):
    BASIC = "basic"      # åŸºç¡€ç­›é€‰ï¼šç¡¬æ€§æ¡ä»¶
    ADVANCED = "advanced"  # é«˜çº§ç­›é€‰ï¼šæ™ºèƒ½è¯„åˆ†

@dataclass
class FilterResult:
    """ç­›é€‰ç»“æœ"""
    score: float  # 0-1åˆ†æ•°
    reason: str   # ç­›é€‰åŸå› 
    details: Dict[str, Any]  # è¯¦ç»†ä¿¡æ¯

class BaseFilter(ABC):
    """ç­›é€‰å™¨åŸºç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.enabled = config.get('enabled', True)
        self.weight = config.get('weight', 1.0)
        self.threshold = config.get('threshold', 0.0)
        self.is_hard_filter = config.get('is_hard_filter', False)  # æ˜¯å¦ä¸ºç¡¬æ€§ç­›é€‰
    
    @abstractmethod
    def filter(self, job: Dict[str, Any]) -> FilterResult:
        """æ‰§è¡Œç­›é€‰"""
        pass
    
    @abstractmethod
    def get_filter_type(self) -> FilterType:
        """è·å–ç­›é€‰ç±»å‹"""
        pass

# ========== åŸºç¡€ç­›é€‰å™¨ï¼ˆç¡¬æ€§æ¡ä»¶ï¼‰ ==========

class SalaryFilter(BaseFilter):
    """è–ªèµ„ç­›é€‰å™¨ - æ”¯æŒç¡¬æ€§ç­›é€‰"""
    
    def get_filter_type(self) -> FilterType:
        return FilterType.BASIC
    
    def filter(self, job: Dict[str, Any]) -> FilterResult:
        salary_text = job.get('è–ªèµ„', '') or self._extract_from_description(job)
        
        if not salary_text:
            return FilterResult(0.5, "æ— è–ªèµ„ä¿¡æ¯", {"salary_range": None})
        
        salary_range = self._parse_salary(salary_text)
        if not salary_range:
            return FilterResult(0.5, "è–ªèµ„è§£æå¤±è´¥", {"salary_text": salary_text})
        
        min_salary, max_salary = salary_range
        
        # ç¡¬æ€§ç­›é€‰é˜ˆå€¼
        hard_min = self.config.get('hard_min_salary', 15)  # æœ€ä½æ¥å—è–ªèµ„
        hard_max = self.config.get('hard_max_salary', 80)  # æœ€é«˜æ¥å—è–ªèµ„
        
        # ç¡¬æ€§ç­›é€‰
        if max_salary < hard_min:
            return FilterResult(0.0, f"è–ªèµ„è¿‡ä½({max_salary}k < {hard_min}k)", 
                              {"salary_range": salary_range, "reject_reason": "below_minimum"})
        
        if min_salary > hard_max:
            return FilterResult(0.0, f"è–ªèµ„è¿‡é«˜({min_salary}k > {hard_max}k)", 
                              {"salary_range": salary_range, "reject_reason": "above_maximum"})
        
        # è½¯æ€§è¯„åˆ†
        target_salary = self.config.get('target_salary', 30)
        mid_salary = (min_salary + max_salary) / 2
        score = self._calculate_salary_score(mid_salary, target_salary)
        
        # ç”Ÿæˆå»ºè®®
        suggestion = self._generate_salary_suggestion(mid_salary, target_salary)
        
        return FilterResult(score, f"è–ªèµ„åŒ¹é…({min_salary}-{max_salary}k)", {
            "salary_range": salary_range,
            "mid_salary": mid_salary,
            "target_salary": target_salary,
            "suggestion": suggestion
        })
    
    def _parse_salary(self, salary_text: str) -> Optional[Tuple[int, int]]:
        """è§£æè–ªèµ„èŒƒå›´"""
        patterns = [
            (r'(\d+)[-~åˆ°](\d+)[kK](?:Â·\d+è–ª)?', 1),  # 20-30kÂ·13è–ª
            (r'(\d+)[-~åˆ°](\d+)ä¸‡(?:Â·\d+è–ª)?', 10),    # 2-3ä¸‡Â·13è–ª
            (r'(\d+)[kK][-~åˆ°](\d+)[kK]', 1),         # 20k-30k
            (r'(\d+)\+[kK]', lambda x: (x, x * 1.3)), # 25k+
            (r'(\d+)ä¸‡\+', lambda x: (x * 10, x * 13)), # 3ä¸‡+
            (r'(\d+)[kK](?:Â·\d+è–ª)?$', lambda x: (x * 0.9, x * 1.1)), # 30kÂ·13è–ª
        ]
        
        for pattern, multiplier in patterns:
            match = re.search(pattern, salary_text)
            if match:
                if callable(multiplier):
                    return multiplier(int(match.group(1)))
                else:
                    min_val = int(match.group(1)) * multiplier
                    max_val = int(match.group(2)) * multiplier
                    return (min_val, max_val)
        
        return None
    
    def _calculate_salary_score(self, mid_salary: float, target_salary: float) -> float:
        """è®¡ç®—è–ªèµ„è¯„åˆ†"""
        ratio = mid_salary / target_salary
        
        if 0.9 <= ratio <= 1.1:
            return 1.0  # å®Œç¾åŒ¹é…
        elif 0.8 <= ratio < 0.9 or 1.1 < ratio <= 1.3:
            return 0.8  # è‰¯å¥½åŒ¹é…
        elif 0.7 <= ratio < 0.8 or 1.3 < ratio <= 1.5:
            return 0.6  # å¯æ¥å—
        else:
            return 0.3  # åå·®è¾ƒå¤§
    
    def _generate_salary_suggestion(self, mid_salary: float, target_salary: float) -> str:
        """ç”Ÿæˆè–ªèµ„å»ºè®®"""
        ratio = mid_salary / target_salary
        
        if ratio >= 1.2:
            return f"è–ªèµ„é«˜äºé¢„æœŸ{(ratio-1)*100:.0f}%ï¼Œä¼˜ç§€æœºä¼š"
        elif ratio >= 1.0:
            return f"è–ªèµ„ç¬¦åˆé¢„æœŸï¼Œæ¨èç”³è¯·"
        elif ratio >= 0.8:
            return f"è–ªèµ„ç•¥ä½äºé¢„æœŸï¼Œå¯è€ƒè™‘å…¶ä»–ä¼˜åŠ¿"
        else:
            return f"è–ªèµ„åä½{(1-ratio)*100:.0f}%ï¼Œè°¨æ…è€ƒè™‘"
    
    def _extract_from_description(self, job: Dict[str, Any]) -> str:
        """ä»å²—ä½æè¿°æå–è–ªèµ„"""
        description = job.get('å²—ä½æè¿°', '')
        patterns = [r'\d+[-~åˆ°]\d+[kKä¸‡]', r'è–ªèµ„[:ï¼š]\s*\d+']
        for pattern in patterns:
            match = re.search(pattern, description)
            if match:
                return match.group(0)
        return ''

class LocationFilter(BaseFilter):
    """å·¥ä½œåœ°ç‚¹ç­›é€‰å™¨ - æ”¯æŒç¡¬æ€§ç­›é€‰"""
    
    def get_filter_type(self) -> FilterType:
        return FilterType.BASIC
    
    def filter(self, job: Dict[str, Any]) -> FilterResult:
        location = job.get('å·¥ä½œåœ°ç‚¹', '').strip()
        if not location:
            return FilterResult(0.5, "æ— åœ°ç‚¹ä¿¡æ¯", {})
        
        preferred_cities = self.config.get('preferred_cities', ['åŒ—äº¬', 'ä¸Šæµ·', 'æ·±åœ³'])
        acceptable_cities = self.config.get('acceptable_cities', ['æ­å·', 'å¹¿å·', 'æˆéƒ½'])
        rejected_cities = self.config.get('rejected_cities', [])
        remote_keywords = ['è¿œç¨‹', 'åœ¨å®¶åŠå…¬', 'remote', 'work from home']
        
        location_lower = location.lower()
        
        # ç¡¬æ€§æ‹’ç»åŸå¸‚
        for city in rejected_cities:
            if city in location:
                return FilterResult(0.0, f"æ‹’ç»åŸå¸‚({city})", {
                    "matched_city": city,
                    "reject_reason": "blacklisted_city"
                })
        
        # è¿œç¨‹å·¥ä½œ
        if any(keyword in location_lower for keyword in remote_keywords):
            return FilterResult(1.0, "è¿œç¨‹å·¥ä½œ", {
                "location_type": "remote",
                "suggestion": "è¿œç¨‹å·¥ä½œï¼Œæ— åœ°ç†é™åˆ¶"
            })
        
        # é¦–é€‰åŸå¸‚
        for city in preferred_cities:
            if city in location:
                return FilterResult(1.0, f"é¦–é€‰åŸå¸‚({city})", {
                    "matched_city": city,
                    "location_type": "preferred",
                    "suggestion": f"{city}æ˜¯é¦–é€‰å·¥ä½œåŸå¸‚"
                })
        
        # å¯æ¥å—åŸå¸‚
        for city in acceptable_cities:
            if city in location:
                return FilterResult(0.8, f"å¯æ¥å—åŸå¸‚({city})", {
                    "matched_city": city,
                    "location_type": "acceptable",
                    "suggestion": f"{city}å¯ä»¥è€ƒè™‘"
                })
        
        return FilterResult(0.4, f"å…¶ä»–åŸå¸‚({location})", {
            "location": location,
            "location_type": "other",
            "suggestion": "éœ€è¦è¯„ä¼°æ¬è¿æˆæœ¬"
        })

class ExperienceFilter(BaseFilter):
    """ç»éªŒè¦æ±‚ç­›é€‰å™¨"""
    
    def get_filter_type(self) -> FilterType:
        return FilterType.BASIC
    
    def filter(self, job: Dict[str, Any]) -> FilterResult:
        experience_text = job.get('ç»éªŒè¦æ±‚', '')
        if not experience_text:
            return FilterResult(0.7, "æ— ç»éªŒè¦æ±‚", {"suggestion": "ç»éªŒè¦æ±‚ä¸æ˜ç¡®ï¼Œå¯å°è¯•ç”³è¯·"})
        
        user_experience = self.config.get('user_experience_years', 1.0)
        parsed = self._parse_experience(experience_text)
        
        if not parsed['parsed_successfully']:
            return FilterResult(0.5, "ç»éªŒè¦æ±‚è§£æå¤±è´¥", {
                **parsed,
                "suggestion": "éœ€è¦äººå·¥åˆ†æç»éªŒè¦æ±‚"
            })
        
        score = self._calculate_experience_score(user_experience, parsed)
        reason = self._generate_experience_reason(user_experience, parsed, score)
        suggestion = self._generate_experience_suggestion(user_experience, parsed, score)
        
        return FilterResult(score, reason, {
            **parsed,
            "user_experience": user_experience,
            "suggestion": suggestion
        })
    
    def _parse_experience(self, text: str) -> Dict[str, Any]:
        """è§£æç»éªŒè¦æ±‚"""
        text_lower = text.lower()
        
        # åº”å±Šç”Ÿ/å®ä¹ ç”Ÿ
        if any(keyword in text_lower for keyword in ['åº”å±Š', 'å®ä¹ ', 'æ ¡æ‹›', 'æ¯•ä¸šç”Ÿ']):
            return {
                "min_years": 0,
                "max_years": 0,
                "is_fresh_grad": True,
                "parsed_successfully": True,
                "requirement_type": "åº”å±Šç”Ÿ"
            }
        
        # ç»éªŒä¸é™
        if any(keyword in text_lower for keyword in ['ä¸é™', 'æ— è¦æ±‚', 'ç»éªŒä¸é™']):
            return {
                "min_years": 0,
                "max_years": None,
                "is_unlimited": True,
                "parsed_successfully": True,
                "requirement_type": "ç»éªŒä¸é™"
            }
        
        # è§£æå…·ä½“å¹´é™
        patterns = [
            (r'(\d+)[-~åˆ°](\d+)å¹´', 'range'),
            (r'(\d+)å¹´ä»¥ä¸Š', 'min_plus'),
            (r'(\d+)\+å¹´', 'min_plus'),
            (r'(\d+)å¹´', 'exact'),
        ]
        
        for pattern, pattern_type in patterns:
            match = re.search(pattern, text)
            if match:
                if pattern_type == 'range':
                    min_years = float(match.group(1))
                    max_years = float(match.group(2))
                elif pattern_type == 'min_plus':
                    min_years = float(match.group(1))
                    max_years = None
                else:  # exact
                    exact_years = float(match.group(1))
                    min_years = max(0, exact_years - 0.5)
                    max_years = exact_years + 0.5
                
                return {
                    "min_years": min_years,
                    "max_years": max_years,
                    "parsed_successfully": True,
                    "requirement_type": f"{pattern_type}_{min_years}"
                }
        
        return {"parsed_successfully": False}
    
    def _calculate_experience_score(self, user_exp: float, parsed: Dict) -> float:
        """è®¡ç®—ç»éªŒåŒ¹é…åˆ†æ•°"""
        if parsed.get('is_fresh_grad'):
            return 0.9 if user_exp <= 2 else 0.5
        
        if parsed.get('is_unlimited'):
            return 0.8
        
        min_req = parsed.get('min_years', 0)
        max_req = parsed.get('max_years')
        
        if max_req is None:  # Xå¹´ä»¥ä¸Š
            if user_exp >= min_req:
                if user_exp <= min_req + 2:
                    return 1.0  # å®Œç¾åŒ¹é…
                else:
                    return 0.8  # è¿‡åº¦åŒ¹é…ä½†å¯æ¥å—
            else:
                gap = min_req - user_exp
                return 0.6 if gap <= 1 else 0.2
        else:  # X-Yå¹´
            if min_req <= user_exp <= max_req:
                return 1.0  # å®Œç¾åŒ¹é…
            elif user_exp < min_req:
                gap = min_req - user_exp
                return 0.6 if gap <= 1 else 0.2
            else:
                return 0.8  # è¿‡åº¦åŒ¹é…
    
    def _generate_experience_reason(self, user_exp: float, parsed: Dict, score: float) -> str:
        """ç”Ÿæˆç»éªŒåŒ¹é…åŸå› """
        if score >= 0.9:
            return f"ç»éªŒå®Œå…¨åŒ¹é…({user_exp}å¹´)"
        elif score >= 0.6:
            return f"ç»éªŒåŸºæœ¬åŒ¹é…({user_exp}å¹´)"
        else:
            return f"ç»éªŒä¸åŒ¹é…({user_exp}å¹´)"
    
    def _generate_experience_suggestion(self, user_exp: float, parsed: Dict, score: float) -> str:
        """ç”Ÿæˆç»éªŒå»ºè®®"""
        if parsed.get('is_fresh_grad'):
            return "é¢å‘åº”å±Šç”Ÿï¼Œé€‚åˆç”³è¯·"
        
        min_req = parsed.get('min_years', 0)
        max_req = parsed.get('max_years')
        
        if score >= 0.9:
            return "ç»éªŒå®Œå…¨ç¬¦åˆè¦æ±‚ï¼Œå¼ºçƒˆæ¨èç”³è¯·"
        elif score >= 0.6:
            return "ç»éªŒåŸºæœ¬ç¬¦åˆï¼Œå¯ä»¥ç”³è¯·"
        else:
            if user_exp < min_req:
                gap = min_req - user_exp
                return f"ç»éªŒä¸è¶³{gap:.1f}å¹´ï¼Œå¯é€šè¿‡é¡¹ç›®ç»éªŒè¡¥å……"
            else:
                return "ç»éªŒè¿‡äºä¸°å¯Œï¼Œå¯èƒ½å­˜åœ¨è¿‡åº¦åŒ¹é…"

class GraduationFilter(BaseFilter):
    """æ¯•ä¸šæ—¶é—´ç­›é€‰å™¨ - ç¡¬æ€§ç­›é€‰"""
    
    def get_filter_type(self) -> FilterType:
        return FilterType.BASIC
    
    def filter(self, job: Dict[str, Any]) -> FilterResult:
        graduation_req = job.get('æ¯•ä¸šæ—¶é—´è¦æ±‚', '')
        if not graduation_req:
            return FilterResult(0.8, "æ— æ¯•ä¸šæ—¶é—´è¦æ±‚", {"suggestion": "æ— æ˜ç¡®æ¯•ä¸šæ—¶é—´è¦æ±‚"})
        
        user_graduation = self.config.get('user_graduation', '2023-12')
        standardized = self._standardize_graduation(graduation_req)
        
        # ç¡¬æ€§ç­›é€‰é€»è¾‘
        if '2024å±Š' in graduation_req and '2023-12' in user_graduation:
            return FilterResult(1.0, "2024å±Šå®Œå…¨åŒ¹é…", {
                "requirement": standardized,
                "match_status": "å®Œå…¨ç¬¦åˆ",
                "suggestion": "æ¯•ä¸šæ—¶é—´å®Œå…¨ç¬¦åˆè¦æ±‚"
            })
        elif '2025å±Š' in graduation_req:
            return FilterResult(0.0, "2025å±Šä¸åŒ¹é…", {
                "requirement": standardized,
                "match_status": "ä¸ç¬¦åˆ",
                "suggestion": "2025å±Šä¸º2024å¹´æ¯•ä¸šï¼Œä¸ç¬¦åˆæ¡ä»¶",
                "reject_reason": "graduation_mismatch"
            })
        elif '2023å±Š' in graduation_req:
            return FilterResult(0.0, "2023å±Šå·²è¿‡æœŸ", {
                "requirement": standardized,
                "match_status": "å·²è¿‡æœŸ",
                "suggestion": "2023å±Šæ‹›è˜å·²ç»“æŸ",
                "reject_reason": "expired_graduation"
            })
        elif any(keyword in graduation_req for keyword in ['åº”å±Š', 'æ ¡æ‹›']):
            return FilterResult(0.8, "åº”å±Šç”Ÿè¦æ±‚", {
                "requirement": standardized,
                "match_status": "éœ€è¦ç¡®è®¤",
                "suggestion": "åº”å±Šç”Ÿæ‹›è˜ï¼Œå»ºè®®æŸ¥çœ‹è¯¦ç»†è¦æ±‚"
            })
        else:
            return FilterResult(0.5, "æ¯•ä¸šæ—¶é—´éœ€ç¡®è®¤", {
                "requirement": standardized,
                "match_status": "éœ€è¦ç¡®è®¤",
                "suggestion": "æ¯•ä¸šæ—¶é—´è¦æ±‚ä¸æ˜ç¡®ï¼Œéœ€è¦äººå·¥ç¡®è®¤"
            })
    
    def _standardize_graduation(self, graduation_req: str) -> str:
        """æ ‡å‡†åŒ–æ¯•ä¸šæ—¶é—´è¦æ±‚"""
        if not graduation_req:
            return ""
        
        # å±Šåˆ«æ ¼å¼ä¿æŒä¸å˜
        if 'å±Š' in graduation_req:
            return graduation_req
        
        # å…¶ä»–æ ¼å¼ç®€å•å¤„ç†
        return graduation_req.strip()

class DeadlineFilter(BaseFilter):
    """æ‹›è˜æˆªæ­¢æ—¥æœŸç­›é€‰å™¨ - ç¡¬æ€§ç­›é€‰"""
    
    def get_filter_type(self) -> FilterType:
        return FilterType.BASIC
    
    def filter(self, job: Dict[str, Any]) -> FilterResult:
        deadline_text = job.get('æ‹›è˜æˆªæ­¢æ—¥æœŸ', '')
        if not deadline_text:
            return FilterResult(0.8, "æ— æˆªæ­¢æ—¥æœŸ", {"suggestion": "æ— æ˜ç¡®æˆªæ­¢æ—¥æœŸï¼Œå»ºè®®å°½å¿«ç”³è¯·"})
        
        # æ ‡å‡†åŒ–æˆªæ­¢æ—¥æœŸ
        standardized_date = self._standardize_date(deadline_text)
        if not standardized_date:
            return FilterResult(0.5, "æˆªæ­¢æ—¥æœŸè§£æå¤±è´¥", {
                "original": deadline_text,
                "suggestion": "æ—¥æœŸæ ¼å¼å¼‚å¸¸ï¼Œéœ€è¦äººå·¥ç¡®è®¤"
            })
        
        # ä¿å­˜æ ‡å‡†åŒ–æ—¥æœŸåˆ°jobå¯¹è±¡
        job['æ‹›è˜æˆªæ­¢æ—¥æœŸ_æ ‡å‡†åŒ–'] = standardized_date
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        try:
            deadline = datetime.strptime(standardized_date, "%Y-%m-%d")
            now = datetime.now()
            days_left = (deadline - now).days
            
            if deadline < now:
                return FilterResult(0.0, "æ‹›è˜å·²æˆªæ­¢", {
                    "deadline": standardized_date,
                    "days_left": days_left,
                    "status": "å·²è¿‡æœŸ",
                    "suggestion": "æ‹›è˜å·²ç»“æŸ",
                    "reject_reason": "expired_deadline"
                })
            elif days_left <= 3:
                return FilterResult(0.7, f"å³å°†æˆªæ­¢({days_left}å¤©)", {
                    "deadline": standardized_date,
                    "days_left": days_left,
                    "status": "å³å°†æˆªæ­¢",
                    "suggestion": f"è¿˜æœ‰{days_left}å¤©æˆªæ­¢ï¼Œéœ€è¦å°½å¿«ç”³è¯·"
                })
            elif days_left <= 7:
                return FilterResult(0.9, f"è¿‘æœŸæˆªæ­¢({days_left}å¤©)", {
                    "deadline": standardized_date,
                    "days_left": days_left,
                    "status": "è¿‘æœŸæˆªæ­¢",
                    "suggestion": f"è¿˜æœ‰{days_left}å¤©æˆªæ­¢ï¼Œå»ºè®®ä¼˜å…ˆç”³è¯·"
                })
            else:
                return FilterResult(1.0, f"å……è£•æ—¶é—´({days_left}å¤©)", {
                    "deadline": standardized_date,
                    "days_left": days_left,
                    "status": "æœªè¿‡æœŸ",
                    "suggestion": f"è¿˜æœ‰{days_left}å¤©æ—¶é—´å‡†å¤‡ç”³è¯·"
                })
                
        except ValueError:
            return FilterResult(0.5, "æ—¥æœŸæ ¼å¼é”™è¯¯", {
                "deadline": standardized_date,
                "suggestion": "æ—¥æœŸæ ¼å¼æ— æ³•è§£æï¼Œéœ€è¦äººå·¥ç¡®è®¤"
            })
    
    def _standardize_date(self, date_str: str) -> Optional[str]:
        """æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼ä¸ºYYYY-MM-DD"""
        if not date_str:
            return None
        
        # ç§»é™¤å‰ç¼€
        text = re.sub(r'^(æˆªæ­¢æ—¥æœŸ|æŠ¥åæˆªæ­¢|ç”³è¯·æˆªæ­¢|æ‹›è˜æˆªæ­¢)[ï¼š:]\s*', '', date_str.strip())
        
        patterns = [
            (r'(\d{4})[./å¹´](\d{1,2})[./æœˆ](\d{1,2})[æ—¥]?', 
             lambda m: f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}"),
            (r'(\d{4})[./å¹´](\d{1,2})[æœˆ]?', 
             lambda m: f"{m.group(1)}-{int(m.group(2)):02d}-01"),
            (r'(\d{4})å¹´?', 
             lambda m: f"{m.group(1)}-01-01"),
            # å¤„ç†ç®€åŒ–å¹´ä»½æ ¼å¼
            (r'(\d{2})[./å¹´](\d{1,2})[./æœˆ](\d{1,2})[æ—¥]?', 
             lambda m: f"20{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}"),
        ]
        
        for pattern, formatter in patterns:
            match = re.search(pattern, text)
            if match:
                try:
                    return formatter(match)
                except:
                    continue
        
        return None

# ========== é«˜çº§ç­›é€‰å™¨ï¼ˆæ™ºèƒ½è¯„åˆ†ï¼‰ ==========

class CompanyFameFilter(BaseFilter):
    """å…¬å¸çŸ¥ååº¦ç­›é€‰å™¨"""
    
    def get_filter_type(self) -> FilterType:
        return FilterType.ADVANCED
    
    def filter(self, job: Dict[str, Any]) -> FilterResult:
        company = job.get('å…¬å¸åç§°', '').strip()
        if not company:
            return FilterResult(0.3, "æ— å…¬å¸ä¿¡æ¯", {})
        
        # çŸ¥åå…¬å¸åˆ†ç±»
        tier1_companies = self.config.get('tier1_companies', [
            'åä¸º', 'è…¾è®¯', 'å­—èŠ‚è·³åŠ¨', 'é˜¿é‡Œå·´å·´', 'ç™¾åº¦', 'ç¾å›¢', 'æ»´æ»´', 'å°ç±³', 'äº¬ä¸œ'
        ])
        
        tier2_companies = self.config.get('tier2_companies', [
            'å•†æ±¤', 'æ—·è§†', 'ä¾å›¾', 'ç¬¬å››èŒƒå¼', 'å¯’æ­¦çºª', 'åœ°å¹³çº¿', 'äº‘ä»', 'æ¾æ€'
        ])
        
        tier3_companies = self.config.get('tier3_companies', [
            'ç½‘æ˜“', 'æœç‹—', '360', 'æ–°æµª', 'æœç‹', 'çˆ±å¥‡è‰º', 'ä¼˜é…·', 'æºç¨‹'
        ])
        
        # åŒ¹é…é€»è¾‘
        for company_name in tier1_companies:
            if company_name in company:
                return FilterResult(1.0, f"é¡¶çº§å¤§å‚({company_name})", {
                    "company_tier": "tier1",
                    "matched_company": company_name,
                    "suggestion": "é¡¶çº§äº’è”ç½‘å…¬å¸ï¼Œå¼ºçƒˆæ¨è"
                })
        
        for company_name in tier2_companies:
            if company_name in company:
                return FilterResult(0.9, f"çŸ¥åAIå…¬å¸({company_name})", {
                    "company_tier": "tier2",
                    "matched_company": company_name,
                    "suggestion": "çŸ¥åAIç‹¬è§’å…½ï¼ŒæŠ€æœ¯å®åŠ›å¼º"
                })
        
        for company_name in tier3_companies:
            if company_name in company:
                return FilterResult(0.8, f"çŸ¥åå…¬å¸({company_name})", {
                    "company_tier": "tier3",
                    "matched_company": company_name,
                    "suggestion": "çŸ¥åäº’è”ç½‘å…¬å¸ï¼Œå¯ä»¥è€ƒè™‘"
                })
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¤§å…¬å¸ï¼ˆé€šè¿‡å…³é”®è¯ï¼‰
        big_company_keywords = ['ç§‘æŠ€', 'é›†å›¢', 'è‚¡ä»½', 'æœ‰é™å…¬å¸']
        if any(keyword in company for keyword in big_company_keywords):
            return FilterResult(0.5, f"æ™®é€šä¼ä¸š({company})", {
                "company_tier": "normal",
                "suggestion": "éœ€è¦è¿›ä¸€æ­¥äº†è§£å…¬å¸èƒŒæ™¯"
            })
        
        return FilterResult(0.3, f"å°å‹å…¬å¸({company})", {
            "company_tier": "small",
            "suggestion": "å°å‹å…¬å¸ï¼Œéœ€è¦è°¨æ…è¯„ä¼°å‘å±•å‰æ™¯"
        })

class BusinessDomainFilter(BaseFilter):
    """ä¸šåŠ¡é¢†åŸŸç­›é€‰å™¨"""
    
    def get_filter_type(self) -> FilterType:
        return FilterType.ADVANCED
    
    def filter(self, job: Dict[str, Any]) -> FilterResult:
        # åˆ†ææ–‡æœ¬
        job_description = job.get('å²—ä½æè¿°', '')
        job_title = job.get('å²—ä½åç§°', '')
        recruitment_direction = job.get('æ‹›å‹Ÿæ–¹å‘', '')
        
        text_to_analyze = f"{job_title} {job_description} {recruitment_direction}"
        
        if not text_to_analyze.strip():
            return FilterResult(0.5, "æ— ä¸šåŠ¡æè¿°", {"suggestion": "ç¼ºå°‘è¯¦ç»†ä¸šåŠ¡æè¿°"})
        
        # ä¸šåŠ¡é¢†åŸŸå…³é”®è¯
        core_domains = self.config.get('core_domains', [
            'å¤§æ¨¡å‹', 'LLM', 'GPT', 'ChatGPT', 'Claude', 'è¯­è¨€æ¨¡å‹'
        ])
        
        ai_domains = self.config.get('ai_domains', [
            'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'äººå·¥æ™ºèƒ½', 'AI', 'ç¥ç»ç½‘ç»œ', 'è‡ªç„¶è¯­è¨€å¤„ç†', 'NLP'
        ])
        
        related_domains = self.config.get('related_domains', [
            'ç®—æ³•', 'æ•°æ®ç§‘å­¦', 'æ¨èç³»ç»Ÿ', 'è®¡ç®—æœºè§†è§‰', 'è¯­éŸ³è¯†åˆ«', 'çŸ¥è¯†å›¾è°±'
        ])
        
        text_lower = text_to_analyze.lower()
        matched_domains = []
        
        # æ ¸å¿ƒé¢†åŸŸåŒ¹é…
        for domain in core_domains:
            if domain.lower() in text_lower:
                matched_domains.append(("core", domain))
        
        # AIé¢†åŸŸåŒ¹é…
        for domain in ai_domains:
            if domain.lower() in text_lower:
                matched_domains.append(("ai", domain))
        
        # ç›¸å…³é¢†åŸŸåŒ¹é…
        for domain in related_domains:
            if domain.lower() in text_lower:
                matched_domains.append(("related", domain))
        
        if not matched_domains:
            return FilterResult(0.3, "æ— åŒ¹é…é¢†åŸŸ", {
                "suggestion": "ä¸šåŠ¡é¢†åŸŸä¸ä¸ªäººæ–¹å‘ä¸å¤ªåŒ¹é…"
            })
        
        # è®¡ç®—åŒ¹é…åˆ†æ•°
        core_matches = [d for t, d in matched_domains if t == "core"]
        ai_matches = [d for t, d in matched_domains if t == "ai"]
        related_matches = [d for t, d in matched_domains if t == "related"]
        
        if core_matches:
            score = 1.0
            reason = f"æ ¸å¿ƒé¢†åŸŸåŒ¹é…({', '.join(core_matches[:2])})"
            suggestion = "ä¸æ ¸å¿ƒæŠ€æœ¯æ–¹å‘é«˜åº¦åŒ¹é…ï¼Œå¼ºçƒˆæ¨è"
        elif ai_matches:
            score = 0.8
            reason = f"AIé¢†åŸŸåŒ¹é…({', '.join(ai_matches[:2])})"
            suggestion = "ä¸AIæŠ€æœ¯æ–¹å‘åŒ¹é…ï¼Œæ¨èç”³è¯·"
        elif related_matches:
            score = 0.6
            reason = f"ç›¸å…³é¢†åŸŸåŒ¹é…({', '.join(related_matches[:2])})"
            suggestion = "ä¸ç›¸å…³æŠ€æœ¯é¢†åŸŸåŒ¹é…ï¼Œå¯ä»¥è€ƒè™‘"
        else:
            score = 0.3
            reason = "æ— æ˜æ˜¾åŒ¹é…"
            suggestion = "æŠ€æœ¯é¢†åŸŸåŒ¹é…åº¦ä¸é«˜"
        
        return FilterResult(score, reason, {
            "matched_domains": matched_domains,
            "core_matches": core_matches,
            "ai_matches": ai_matches,
            "related_matches": related_matches,
            "suggestion": suggestion
        })

# ========== ç­›é€‰ç®¡ç†å™¨ ==========

class UnifiedJobFilterManager:
    """ç»Ÿä¸€çš„å²—ä½ç­›é€‰ç®¡ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.basic_filters = self._init_basic_filters()
        self.advanced_filters = self._init_advanced_filters()
        
        print(f"âœ… ç»Ÿä¸€ç­›é€‰å™¨åˆå§‹åŒ–å®Œæˆ: {len(self.basic_filters)}ä¸ªåŸºç¡€ç­›é€‰å™¨, {len(self.advanced_filters)}ä¸ªé«˜çº§ç­›é€‰å™¨")
    
    def _init_basic_filters(self) -> Dict[str, BaseFilter]:
        """åˆå§‹åŒ–åŸºç¡€ç­›é€‰å™¨"""
        basic_config = self.config.get('basic', {})
        enabled_filters = basic_config.get('enabled', 
            ['salary', 'location', 'experience', 'graduation', 'deadline'])
        
        filters = {}
        filter_classes = {
            'salary': SalaryFilter,
            'location': LocationFilter,
            'experience': ExperienceFilter,
            'graduation': GraduationFilter,
            'deadline': DeadlineFilter
        }
        
        for filter_name in enabled_filters:
            if filter_name in filter_classes:
                filter_config = basic_config.get(filter_name, {})
                # åˆå¹¶å…¬å…±é…ç½®
                filter_config.update(basic_config.get('common', {}))
                filters[filter_name] = filter_classes[filter_name](filter_config)
        
        return filters
    
    def _init_advanced_filters(self) -> Dict[str, BaseFilter]:
        """åˆå§‹åŒ–é«˜çº§ç­›é€‰å™¨"""
        advanced_config = self.config.get('advanced', {})
        enabled_filters = advanced_config.get('enabled', ['company_fame', 'business_domain'])
        
        filters = {}
        filter_classes = {
            'company_fame': CompanyFameFilter,
            'business_domain': BusinessDomainFilter
        }
        
        for filter_name in enabled_filters:
            if filter_name in filter_classes:
                filter_config = advanced_config.get(filter_name, {})
                filters[filter_name] = filter_classes[filter_name](filter_config)
        
        return filters
    
    def apply_basic_filters(self, jobs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åº”ç”¨åŸºç¡€ç­›é€‰å™¨ - ç¡¬æ€§ç­›é€‰"""
        if not jobs:
            return []
        
        print(f"ğŸ” å¼€å§‹åŸºç¡€ç­›é€‰: {len(jobs)}ä¸ªå²—ä½")
        
        filtered_jobs = []
        hard_filter_count = 0
        basic_config = self.config.get('basic', {})
        global_threshold = basic_config.get('global_threshold', 0.3)
        
        for job in jobs:
            scores = {}
            total_score = 0
            total_weight = 0
            hard_filter_failed = False
            
            # åº”ç”¨æ‰€æœ‰åŸºç¡€ç­›é€‰å™¨
            for filter_name, filter_obj in self.basic_filters.items():
                if not filter_obj.enabled:
                    continue
                
                result = filter_obj.filter(job)
                scores[filter_name] = result
                
                # ç¡¬æ€§ç­›é€‰æ£€æŸ¥ - scoreä¸º0è¡¨ç¤ºç¡¬æ€§æ‹’ç»
                if result.score == 0.0:
                    hard_filter_failed = True
                    hard_filter_count += 1
                    print(f"   âŒ ç¡¬æ€§ç­›é€‰æ‹’ç»: {job.get('å²—ä½åç§°', 'N/A')} - {result.reason}")
                    break
                
                # åŠ æƒè®¡ç®—
                total_score += result.score * filter_obj.weight
                total_weight += filter_obj.weight
            
            # ç¡¬æ€§ç­›é€‰æœªé€šè¿‡ï¼Œç›´æ¥è·³è¿‡
            if hard_filter_failed:
                continue
            
            # è®¡ç®—ç»¼åˆåˆ†æ•°
            final_score = total_score / total_weight if total_weight > 0 else 0
            
            # è½¯æ€§ç­›é€‰é˜ˆå€¼æ£€æŸ¥
            if final_score >= global_threshold:
                job['_basic_filter_score'] = final_score
                job['_basic_filter_details'] = scores
                filtered_jobs.append(job)
                print(f"   âœ… åŸºç¡€ç­›é€‰é€šè¿‡: {job.get('å²—ä½åç§°', 'N/A')} (åˆ†æ•°: {final_score:.2f})")
            else:
                print(f"   âš ï¸  åˆ†æ•°è¿‡ä½: {job.get('å²—ä½åç§°', 'N/A')} (åˆ†æ•°: {final_score:.2f} < {global_threshold})")
        
        print(f"âœ… åŸºç¡€ç­›é€‰å®Œæˆ: {len(filtered_jobs)}/{len(jobs)}ä¸ªå²—ä½é€šè¿‡")
        print(f"   ç¡¬æ€§ç­›é€‰è¿‡æ»¤: {hard_filter_count}ä¸ªå²—ä½")
        print(f"   è½¯æ€§ç­›é€‰è¿‡æ»¤: {len(jobs) - len(filtered_jobs) - hard_filter_count}ä¸ªå²—ä½")
        
        return filtered_jobs
    
    def apply_advanced_filters(self, jobs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åº”ç”¨é«˜çº§ç­›é€‰å™¨ - æ™ºèƒ½è¯„åˆ†æ’åº"""
        if not jobs:
            return []
        
        print(f"ğŸ” å¼€å§‹é«˜çº§ç­›é€‰: {len(jobs)}ä¸ªå²—ä½")
        
        for job in jobs:
            scores = {}
            total_score = 0
            total_weight = 0
            
            # åº”ç”¨æ‰€æœ‰é«˜çº§ç­›é€‰å™¨
            for filter_name, filter_obj in self.advanced_filters.items():
                if not filter_obj.enabled:
                    continue
                
                result = filter_obj.filter(job)
                scores[filter_name] = result
                
                # åŠ æƒè®¡ç®—
                total_score += result.score * filter_obj.weight
                total_weight += filter_obj.weight
            
            # è®¡ç®—é«˜çº§ç­›é€‰åˆ†æ•°
            advanced_score = total_score / total_weight if total_weight > 0 else 0.5
            
            # åˆå¹¶åŸºç¡€å’Œé«˜çº§åˆ†æ•°
            basic_score = job.get('_basic_filter_score', 0.5)
            basic_weight = self.config.get('score_weights', {}).get('basic', 0.6)
            advanced_weight = self.config.get('score_weights', {}).get('advanced', 0.4)
            
            final_score = basic_score * basic_weight + advanced_score * advanced_weight
            
            # ä¿å­˜è¯„åˆ†ä¿¡æ¯
            job['ç»¼åˆè¯„åˆ†'] = round(final_score * 100)  # è½¬ä¸º0-100åˆ†
            job['æ¨èç­‰çº§'] = self._get_recommendation_level(final_score)
            job['_advanced_filter_details'] = scores
            job['_final_score'] = final_score
            
            # ç”ŸæˆåŒ¹é…å»ºè®®
            job['åŒ¹é…å»ºè®®'] = self._generate_match_suggestion(job, scores)
        
        # æŒ‰åˆ†æ•°æ’åº
        jobs.sort(key=lambda x: x.get('_final_score', 0), reverse=True)
        
        print(f"âœ… é«˜çº§ç­›é€‰å®Œæˆ: {len(jobs)}ä¸ªå²—ä½å·²è¯„åˆ†æ’åº")
        self._print_score_distribution(jobs)
        
        return jobs
    
    def _get_recommendation_level(self, score: float) -> str:
        """è·å–æ¨èç­‰çº§"""
        if score >= 0.8:
            return "ğŸŒŸ å¼ºçƒˆæ¨è"
        elif score >= 0.65:
            return "âœ¨ æ¨è"
        elif score >= 0.5:
            return "âš ï¸ å¯è€ƒè™‘"
        else:
            return "âŒ ä¸æ¨è"
    
    def _generate_match_suggestion(self, job: Dict[str, Any], advanced_scores: Dict) -> str:
        """ç”ŸæˆåŒ¹é…å»ºè®®"""
        suggestions = []
        
        # ä»åŸºç¡€ç­›é€‰è·å–å»ºè®®
        basic_details = job.get('_basic_filter_details', {})
        for filter_name, result in basic_details.items():
            if result.details.get('suggestion'):
                suggestions.append(result.details['suggestion'])
        
        # ä»é«˜çº§ç­›é€‰è·å–å»ºè®®
        for filter_name, result in advanced_scores.items():
            if result.details.get('suggestion'):
                suggestions.append(result.details['suggestion'])
        
        # ç»¼åˆå»ºè®®
        final_score = job.get('_final_score', 0)
        if final_score >= 0.8:
            suggestions.insert(0, "ç»¼åˆåŒ¹é…åº¦å¾ˆé«˜ï¼Œå¼ºçƒˆå»ºè®®ç”³è¯·")
        elif final_score >= 0.65:
            suggestions.insert(0, "æ•´ä½“åŒ¹é…è¾ƒå¥½ï¼Œå»ºè®®ç”³è¯·")
        elif final_score >= 0.5:
            suggestions.insert(0, "æœ‰ä¸€å®šåŒ¹é…åº¦ï¼Œå¯ä»¥è€ƒè™‘")
        else:
            suggestions.insert(0, "åŒ¹é…åº¦ä¸é«˜ï¼Œéœ€è¦è°¨æ…è€ƒè™‘")
        
        return " | ".join(suggestions[:3])  # é™åˆ¶å»ºè®®æ•°é‡
    
    def _print_score_distribution(self, jobs: List[Dict[str, Any]]):
        """æ‰“å°åˆ†æ•°åˆ†å¸ƒ"""
        if not jobs:
            return
        
        levels = {}
        for job in jobs:
            level = job.get('æ¨èç­‰çº§', 'Unknown')
            levels[level] = levels.get(level, 0) + 1
        
        print(f"ğŸ“Š æ¨èç­‰çº§åˆ†å¸ƒ:")
        for level, count in levels.items():
            print(f"   {level}: {count}ä¸ªå²—ä½")

# ========== é…ç½®ç®¡ç† ==========

def get_unified_filter_config() -> Dict[str, Any]:
    """è·å–ç»Ÿä¸€çš„ç­›é€‰é…ç½®"""
    return {
        "basic": {
            "enabled": ["salary", "location", "experience", "graduation", "deadline"],
            "global_threshold": 0.3,  # åŸºç¡€ç­›é€‰å…¨å±€é˜ˆå€¼
            
            # å…¬å…±é…ç½®
            "common": {
                "user_experience_years": 1.0,  # ç”¨æˆ·å·¥ä½œç»éªŒå¹´é™
                "user_graduation": "2023-12"   # ç”¨æˆ·æ¯•ä¸šæ—¶é—´
            },
            
            # è–ªèµ„ç­›é€‰é…ç½®
            "salary": {
                "hard_min_salary": 15,    # ç¡¬æ€§æœ€ä½è–ªèµ„
                "hard_max_salary": 80,    # ç¡¬æ€§æœ€é«˜è–ªèµ„
                "target_salary": 30,      # ç›®æ ‡è–ªèµ„
                "weight": 0.3,
                "is_hard_filter": False   # ä¸å¯ç”¨ç¡¬æ€§ç­›é€‰
            },
            
            # åœ°ç‚¹ç­›é€‰é…ç½®
            "location": {
                "preferred_cities": ["åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³"],
                "acceptable_cities": ["æ­å·", "å¹¿å·", "æˆéƒ½", "æ­¦æ±‰", "è¥¿å®‰", "å—äº¬"],
                "rejected_cities": [],     # æ‹’ç»çš„åŸå¸‚
                "weight": 0.2,
                "is_hard_filter": True    # å¯ç”¨ç¡¬æ€§ç­›é€‰
            },
            
            # ç»éªŒç­›é€‰é…ç½®
            "experience": {
                "weight": 0.3,
                "is_hard_filter": False
            },
            
            # æ¯•ä¸šæ—¶é—´ç­›é€‰é…ç½®
            "graduation": {
                "weight": 0.1,
                "is_hard_filter": True    # å¯ç”¨ç¡¬æ€§ç­›é€‰
            },
            
            # æˆªæ­¢æ—¥æœŸç­›é€‰é…ç½®
            "deadline": {
                "weight": 0.1,
                "is_hard_filter": True    # å¯ç”¨ç¡¬æ€§ç­›é€‰
            }
        },
        
        "advanced": {
            "enabled": ["company_fame", "business_domain"],
            
            # å…¬å¸çŸ¥ååº¦ç­›é€‰
            "company_fame": {
                "tier1_companies": [
                    "åä¸º", "è…¾è®¯", "å­—èŠ‚è·³åŠ¨", "é˜¿é‡Œå·´å·´", "ç™¾åº¦", "ç¾å›¢", 
                    "æ»´æ»´", "å°ç±³", "äº¬ä¸œ", "ç½‘æ˜“", "æ‹¼å¤šå¤š", "å¿«æ‰‹"
                ],
                "tier2_companies": [
                    "å•†æ±¤", "æ—·è§†", "ä¾å›¾", "ç¬¬å››èŒƒå¼", "å¯’æ­¦çºª", "åœ°å¹³çº¿",
                    "äº‘ä»", "æ¾æ€", "æ€å¿…é©°", "å‡ºé—¨é—®é—®", "ç«¹é—´æ™ºèƒ½"
                ],
                "tier3_companies": [
                    "æœç‹—", "360", "æ–°æµª", "æœç‹", "çˆ±å¥‡è‰º", "ä¼˜é…·", 
                    "æºç¨‹", "å»å“ªå„¿", "åŒç¨‹", "é©¬èœ‚çª"
                ],
                "weight": 0.4
            },
            
            # ä¸šåŠ¡é¢†åŸŸç­›é€‰
            "business_domain": {
                "core_domains": [
                    "å¤§æ¨¡å‹", "LLM", "GPT", "ChatGPT", "Claude", "è¯­è¨€æ¨¡å‹",
                    "AIGC", "ç”Ÿæˆå¼AI", "å¤šæ¨¡æ€", "é¢„è®­ç»ƒ"
                ],
                "ai_domains": [
                    "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "äººå·¥æ™ºèƒ½", "AI", "ç¥ç»ç½‘ç»œ",
                    "è‡ªç„¶è¯­è¨€å¤„ç†", "NLP", "è®¡ç®—æœºè§†è§‰", "CV"
                ],
                "related_domains": [
                    "ç®—æ³•", "æ•°æ®ç§‘å­¦", "æ¨èç³»ç»Ÿ", "æœç´¢å¼•æ“", "è¯­éŸ³è¯†åˆ«",
                    "çŸ¥è¯†å›¾è°±", "å¼ºåŒ–å­¦ä¹ ", "è”é‚¦å­¦ä¹ "
                ],
                "weight": 0.6
            }
        },
        
        # åˆ†æ•°æƒé‡é…ç½®
        "score_weights": {
            "basic": 0.6,      # åŸºç¡€ç­›é€‰æƒé‡
            "advanced": 0.4    # é«˜çº§ç­›é€‰æƒé‡
        }
    }

def load_unified_filter_config(config_path: str = None) -> Dict[str, Any]:
    """åŠ è½½ç»Ÿä¸€ç­›é€‰é…ç½®"""
    default_config = get_unified_filter_config()
    
    if config_path and os.path.exists(config_path):
        try:
            import yaml
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = yaml.safe_load(f)
            
            # æ·±åº¦åˆå¹¶é…ç½®
            def deep_merge(default, user):
                for key, value in user.items():
                    if key in default and isinstance(default[key], dict) and isinstance(value, dict):
                        deep_merge(default[key], value)
                    else:
                        default[key] = value
            
            if user_config:
                deep_merge(default_config, user_config)
            print(f"âœ… æˆåŠŸåŠ è½½ç”¨æˆ·é…ç½®: {config_path}")
            
        except Exception as e:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
    
    return default_config

# ========== Notionå­—æ®µä¼˜åŒ– ==========

def create_optimized_notion_properties(job_data: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ›å»ºä¼˜åŒ–åçš„Notionå±æ€§ - åªä¿ç•™14ä¸ªæ ¸å¿ƒå­—æ®µ"""
    properties = {}
    
    # 1. æ ¸å¿ƒä¿¡æ¯ (6ä¸ªå­—æ®µ)
    if job_data.get("å²—ä½åç§°"):
        properties["å²—ä½åç§°"] = {
            "title": [{"text": {"content": job_data["å²—ä½åç§°"]}}]
        }
    
    for field in ["å…¬å¸åç§°", "è–ªèµ„", "å·¥ä½œåœ°ç‚¹"]:
        if job_data.get(field):
            properties[field] = {
                "rich_text": [{"text": {"content": str(job_data[field])}}]
            }
    
    if job_data.get("å²—ä½æè¿°"):
        content = job_data["å²—ä½æè¿°"]
        if len(content) > 2000:
            content = content[:1997] + "..."
        properties["å²—ä½æè¿°"] = {
            "rich_text": [{"text": {"content": content}}]
        }
    
    if job_data.get("å²—ä½é“¾æ¥"):
        properties["å²—ä½é“¾æ¥"] = {"url": job_data["å²—ä½é“¾æ¥"]}
    
    # 2. ç­›é€‰è¯„åˆ† (3ä¸ªå­—æ®µ)
    if job_data.get("ç»¼åˆè¯„åˆ†") is not None:
        properties["ç»¼åˆè¯„åˆ†"] = {"number": job_data["ç»¼åˆè¯„åˆ†"]}
    
    if job_data.get("æ¨èç­‰çº§"):
        properties["æ¨èç­‰çº§"] = {
            "select": {"name": job_data["æ¨èç­‰çº§"]}
        }
    
    if job_data.get("åŒ¹é…å»ºè®®"):
        content = job_data["åŒ¹é…å»ºè®®"]
        if len(content) > 2000:
            content = content[:1997] + "..."
        properties["åŒ¹é…å»ºè®®"] = {
            "rich_text": [{"text": {"content": content}}]
        }
    
    # 3. å…³é”®åŒ¹é…ä¿¡æ¯ (3ä¸ªå­—æ®µ)
    if job_data.get("ç»éªŒè¦æ±‚"):
        properties["ç»éªŒè¦æ±‚"] = {
            "rich_text": [{"text": {"content": job_data["ç»éªŒè¦æ±‚"]}}]
        }
    
    # æ¯•ä¸šæ—¶é—´è¦æ±‚ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–ç‰ˆæœ¬ï¼‰
    graduation_req = job_data.get("æ¯•ä¸šæ—¶é—´è¦æ±‚_æ ‡å‡†åŒ–") or job_data.get("æ¯•ä¸šæ—¶é—´è¦æ±‚", "")
    if graduation_req:
        properties["æ¯•ä¸šæ—¶é—´è¦æ±‚"] = {
            "rich_text": [{"text": {"content": graduation_req}}]
        }
    
    # æ‹›è˜æˆªæ­¢æ—¥æœŸï¼ˆä¼˜å…ˆä½¿ç”¨æ ‡å‡†åŒ–ç‰ˆæœ¬ï¼‰
    deadline = job_data.get("æ‹›è˜æˆªæ­¢æ—¥æœŸ_æ ‡å‡†åŒ–") or job_data.get("æ‹›è˜æˆªæ­¢æ—¥æœŸ", "")
    if deadline:
        try:
            # å°è¯•ä½œä¸ºæ—¥æœŸå­—æ®µ
            datetime.strptime(deadline, "%Y-%m-%d")
            properties["æ‹›è˜æˆªæ­¢æ—¥æœŸ"] = {
                "date": {"start": deadline}
            }
        except ValueError:
            # æ ¼å¼é”™è¯¯æ—¶ä½œä¸ºæ–‡æœ¬
            properties["æ‹›è˜æˆªæ­¢æ—¥æœŸ"] = {
                "rich_text": [{"text": {"content": deadline}}]
            }
    
    # 4. è¡¥å……ä¿¡æ¯ (2ä¸ªå­—æ®µ)
    if job_data.get("å‘å¸ƒå¹³å°"):
        properties["å‘å¸ƒå¹³å°"] = {
            "select": {"name": job_data["å‘å¸ƒå¹³å°"]}
        }
    
    if job_data.get("æ‹›å‹Ÿæ–¹å‘"):
        properties["æ‹›å‹Ÿæ–¹å‘"] = {
            "rich_text": [{"text": {"content": job_data["æ‹›å‹Ÿæ–¹å‘"]}}]
        }
    
    return properties

def get_optimized_notion_fields() -> Dict[str, str]:
    """è·å–ä¼˜åŒ–åçš„Notionå­—æ®µå®šä¹‰ï¼ˆå…±14ä¸ªå­—æ®µï¼‰"""
    return {
        # æ ¸å¿ƒä¿¡æ¯ (6ä¸ª)
        "å²—ä½åç§°": "title",
        "å…¬å¸åç§°": "rich_text",
        "è–ªèµ„": "rich_text",
        "å·¥ä½œåœ°ç‚¹": "rich_text",
        "å²—ä½æè¿°": "rich_text",
        "å²—ä½é“¾æ¥": "url",
        
        # ç­›é€‰è¯„åˆ† (3ä¸ª)
        "ç»¼åˆè¯„åˆ†": "number",
        "æ¨èç­‰çº§": "select",
        "ç»éªŒåŒ¹é…å»ºè®®": "rich_text",
        
        # å…³é”®åŒ¹é…ä¿¡æ¯ (3ä¸ª)
        "ç»éªŒè¦æ±‚": "rich_text",
        "æ¯•ä¸šæ—¶é—´è¦æ±‚": "rich_text",
        "æ‹›è˜æˆªæ­¢æ—¥æœŸ": "date",  # å¯ä»¥æ˜¯dateæˆ–rich_text
        
        # è¡¥å……ä¿¡æ¯ (2ä¸ª)
        "å‘å¸ƒå¹³å°": "select",
        "æ‹›å‹Ÿæ–¹å‘": "rich_text"
    }

# ========== æµ‹è¯•å‡½æ•° ==========

def test_unified_filter_system():
    """æµ‹è¯•ç»Ÿä¸€ç­›é€‰ç³»ç»Ÿ"""
    print("ğŸ§ª æµ‹è¯•ç»Ÿä¸€ç­›é€‰ç³»ç»Ÿ...")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    config = get_unified_filter_config()
    filter_manager = UnifiedJobFilterManager(config)
    
    # æµ‹è¯•æ•°æ®
    test_jobs = [
        {
            "å²—ä½åç§°": "æœºå™¨å­¦ä¹ ç®—æ³•å·¥ç¨‹å¸ˆ",
            "å…¬å¸åç§°": "åä¸ºæŠ€æœ¯æœ‰é™å…¬å¸",
            "å·¥ä½œåœ°ç‚¹": "åŒ—äº¬",
            "è–ªèµ„": "25-35k",
            "ç»éªŒè¦æ±‚": "1-3å¹´å·¥ä½œç»éªŒ",
            "æ¯•ä¸šæ—¶é—´è¦æ±‚": "2024å±Šæ¯•ä¸šç”Ÿ",
            "æ‹›è˜æˆªæ­¢æ—¥æœŸ": "2024-12-31",
            "å²—ä½æè¿°": "è´Ÿè´£å¤§æ¨¡å‹ç›¸å…³ç®—æ³•ç ”å‘ï¼Œè¦æ±‚ç†Ÿæ‚‰æ·±åº¦å­¦ä¹ æ¡†æ¶PyTorchï¼Œå‚ä¸LLMé¢„è®­ç»ƒå’Œå¾®è°ƒå·¥ä½œ",
            "æ‹›å‹Ÿæ–¹å‘": "å¤§æ¨¡å‹ç®—æ³•æ–¹å‘"
        },
        {
            "å²—ä½åç§°": "é«˜çº§ç®—æ³•å·¥ç¨‹å¸ˆ", 
            "å…¬å¸åç§°": "æŸåˆ›ä¸šå…¬å¸",
            "å·¥ä½œåœ°ç‚¹": "æˆéƒ½",
            "è–ªèµ„": "15-20k",  # è–ªèµ„è¿‡ä½
            "ç»éªŒè¦æ±‚": "5å¹´ä»¥ä¸Šç»éªŒ",  # ç»éªŒè¦æ±‚è¿‡é«˜
            "æ¯•ä¸šæ—¶é—´è¦æ±‚": "2025å±Š",  # æ¯•ä¸šæ—¶é—´ä¸åŒ¹é…
            "å²—ä½æè¿°": "è´Ÿè´£ä¼ ç»Ÿæ¨èç®—æ³•ä¼˜åŒ–"
        },
        {
            "å²—ä½åç§°": "AIå·¥ç¨‹å¸ˆ",
            "å…¬å¸åç§°": "è…¾è®¯ç§‘æŠ€",
            "å·¥ä½œåœ°ç‚¹": "æ·±åœ³", 
            "è–ªèµ„": "30-45k",
            "ç»éªŒè¦æ±‚": "åº”å±Šæ¯•ä¸šç”Ÿ",
            "æ¯•ä¸šæ—¶é—´è¦æ±‚": "2024å±Š",
            "æ‹›è˜æˆªæ­¢æ—¥æœŸ": "2024-01-01",  # å·²è¿‡æœŸ
            "å²—ä½æè¿°": "å‚ä¸AIå¤§æ¨¡å‹è®­ç»ƒå’Œæ¨ç†ä¼˜åŒ–å·¥ä½œï¼Œè´Ÿè´£ChatGPTç±»äº§å“çš„ç®—æ³•ç ”å‘"
        },
        {
            "å²—ä½åç§°": "æ·±åº¦å­¦ä¹ å·¥ç¨‹å¸ˆ",
            "å…¬å¸åç§°": "å­—èŠ‚è·³åŠ¨",
            "å·¥ä½œåœ°ç‚¹": "åŒ—äº¬",
            "è–ªèµ„": "28-40k",
            "ç»éªŒè¦æ±‚": "1-2å¹´ç»éªŒ",
            "æ¯•ä¸šæ—¶é—´è¦æ±‚": "2024å±Š",
            "æ‹›è˜æˆªæ­¢æ—¥æœŸ": "2024-06-30",
            "å²—ä½æè¿°": "è´Ÿè´£æŠ–éŸ³æ¨èç®—æ³•ä¼˜åŒ–ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ",
            "æ‹›å‹Ÿæ–¹å‘": "æ¨èç®—æ³•æ–¹å‘"
        }
    ]
    
    print(f"ğŸ“‹ åŸå§‹æµ‹è¯•æ•°æ®: {len(test_jobs)} ä¸ªå²—ä½")
    
    # ç¬¬ä¸€æ­¥ï¼šåŸºç¡€ç­›é€‰
    print(f"\n" + "="*20 + " åŸºç¡€ç­›é€‰ " + "="*20)
    basic_filtered = filter_manager.apply_basic_filters(test_jobs)
    
    if not basic_filtered:
        print("âŒ æ²¡æœ‰å²—ä½é€šè¿‡åŸºç¡€ç­›é€‰")
        return
    
    # ç¬¬äºŒæ­¥ï¼šé«˜çº§ç­›é€‰
    print(f"\n" + "="*20 + " é«˜çº§ç­›é€‰ " + "="*20)
    final_filtered = filter_manager.apply_advanced_filters(basic_filtered)
    
    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    print(f"\n" + "="*20 + " æœ€ç»ˆç»“æœ " + "="*20)
    print(f"ğŸ“Š ç­›é€‰ç»“æœ: {len(final_filtered)}/{len(test_jobs)} ä¸ªå²—ä½é€šè¿‡ç­›é€‰")
    
    if final_filtered:
        print(f"\nğŸ† æ¨èå²—ä½æ’åº:")
        for i, job in enumerate(final_filtered, 1):
            print(f"\n{i}. {job['å²—ä½åç§°']} - {job['å…¬å¸åç§°']}")
            print(f"   ğŸ“ åœ°ç‚¹: {job.get('å·¥ä½œåœ°ç‚¹', 'N/A')}")
            print(f"   ğŸ’° è–ªèµ„: {job.get('è–ªèµ„', 'N/A')}")
            print(f"   ğŸ“Š ç»¼åˆè¯„åˆ†: {job['ç»¼åˆè¯„åˆ†']}åˆ†")
            print(f"   â­ æ¨èç­‰çº§: {job['æ¨èç­‰çº§']}")
            print(f"   ğŸ’¡ åŒ¹é…å»ºè®®: {job.get('åŒ¹é…å»ºè®®', 'N/A')}")
    
    print(f"\nâœ… ç»Ÿä¸€ç­›é€‰ç³»ç»Ÿæµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    test_unified_filter_system()